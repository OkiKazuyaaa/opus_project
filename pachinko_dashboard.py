import streamlit as st
st.set_page_config(page_title="å£²ä¸ŠAIåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", layout="wide")
import pandas as pd
import altair as alt
import math
import folium
import shap
import os
import json
import joblib
import numpy as np
import tempfile
import random
from scipy.stats import linregress
from io import StringIO
from folium.plugins import HeatMap
from streamlit_folium import folium_static
from datetime import date, timedelta
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from fpdf import FPDF
import matplotlib.font_manager as fm
import streamlit.components.v1 as components
import base64
import time
from datetime import datetime
import csv
from datetime import datetime, timedelta
import bcrypt
from catboost import CatBoostRegressor
import jpholiday
import pandas as pd
import seaborn as sns



# def build_features(df):
#     import numpy as np
#     import jpholiday
#     df_feat = df.copy()
#     df_feat["æ—¥ä»˜"] = pd.to_datetime(df_feat["æ—¥ä»˜"])
#     df_feat["æ›œæ—¥_x"] = df_feat["æ—¥ä»˜"].dt.strftime("%A")
#     df_feat["ç¥æ—¥å"] = df_feat["æ—¥ä»˜"].apply(lambda x: jpholiday.is_holiday_name(x) if jpholiday.is_holiday(x) else "å¹³æ—¥")
#     df_feat["ç¥æ—¥ãƒ•ãƒ©ã‚°"] = df_feat["ç¥æ—¥å"].apply(lambda x: int(x != "å¹³æ—¥"))
#     df_feat["çµ¦æ–™æ—¥å‰ãƒ•ãƒ©ã‚°"] = df_feat["æ—¥ä»˜"].dt.day.isin([24, 25, 26]).astype(int)

#     #df_feat["é€±ç•ªå·"] = df_feat["æ—¥ä»˜"].dt.isocalendar().week.astype(int)

#     # å¤©æ°—ã‚«ãƒ©ãƒ è£œå®Œï¼ˆäºˆæ¸¬æ™‚ã¯æ¬ æã«ãªã‚‹å¯èƒ½æ€§ã‚ã‚Šï¼‰
#     weather_cols = ["å¹³å‡æ°—æ¸©", "æœ€é«˜æ°—æ¸©", "æœ€ä½æ°—æ¸©", "æ—¥ç…§æ™‚é–“(æ™‚é–“)", "å¹³å‡ç¾åœ°æ°—åœ§(hPa)", "é™æ°´é‡"]
#     for col in weather_cols:
#         if col not in df_feat.columns:
#             df_feat[col] = np.nan

#     return df_feat



# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ ---
with open("users.json", "r", encoding="utf-8") as f:
    USER_DB = json.load(f)

#ãƒ­ã‚°ã‚¤ãƒ³è¨˜éŒ²
if "login_failures" not in st.session_state:
    st.session_state.login_failures = 0

if "login_locked_until" not in st.session_state:
    st.session_state.login_locked_until = None

# --- åº—èˆ—åã®å–å¾—ã¨ãƒãƒƒãƒ”ãƒ³ã‚° ---
store_name = st.session_state.get("store_name", "åº—èˆ—åæœªè¨­å®š")

# --- æ—¥æœ¬èªè¡¨ç¤ºåï¼ˆst.session_stateã«ã‚ã‚‹ï¼‰â†’ ãƒãƒƒãƒ”ãƒ³ã‚°åï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ç”¨ï¼‰ã«å¤‰æ›
store_name_map = {
    "å®®å´æœ¬åº—": "ã‚ªãƒ¼ãƒ‘ã‚¹å®®å´æœ¬åº—",
    "å°æ¾å°åº—": "ã‚ªãƒ¼ãƒ‘ã‚¹å°æ¾",
    "éƒ½åŸåº—": "ã‚ªãƒ¼ãƒ‘ã‚¹éƒ½åŸ",
    "é«˜é‹åº—": "ã‚ªãƒ¼ãƒ‘ã‚¹é«˜é‹",
    "æ—¥å—åº—": "ã‚ªãƒ¼ãƒ‘ã‚¹æ—¥å—",
    "å»¶å²¡åº—": "ã‚ªãƒ¼ãƒ‘ã‚¹å»¶å²¡",
    "ä¸‰è‚¡åº—": "ã‚ªãƒ¼ãƒ‘ã‚¹ä¸‰è‚¡",
    "é¹¿å±‹åº—": "ã‚ªãƒ¼ãƒ‘ã‚¹é¹¿å±‹",
}

mapped_store = store_name_map.get(store_name, store_name)


#æ“ä½œå±¥æ­´
def log_page_visit(page_name):
    file_path = "page_access_log.csv"
    file_exists = os.path.isfile(file_path)

    with open(file_path, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow(["æ—¥æ™‚", "ãƒ¦ãƒ¼ã‚¶ãƒ¼", "åº—èˆ—å", "ãƒšãƒ¼ã‚¸å"])
        writer.writerow([
            datetime.now().isoformat(),
            st.session_state.get("username", "æœªãƒ­ã‚°ã‚¤ãƒ³"),
            st.session_state.get("store_name", "ä¸æ˜åº—èˆ—"),
            page_name
        ])



# --- IPã‚¢ãƒ‰ãƒ¬ã‚¹å–å¾— ---
import requests

def get_client_ip():
    try:
        res = requests.get("https://api.ipify.org?format=json", timeout=3)
        return res.json().get("ip", "ä¸æ˜")
    except:
        return "å–å¾—å¤±æ•—"



# ãƒ•ã‚©ãƒ³ãƒˆãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã§æŒ‡å®š
font_path = os.path.abspath("fonts/NotoSansJP-Regular.otf")

if os.path.exists(font_path):
    fm.fontManager.addfont(font_path)
    plt.rcParams['font.sans-serif'] = ['Noto Sans JP']
    plt.rcParams['axes.unicode_minus'] = False
else:
    st.warning(f"ãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {font_path}")

# ãƒ­ã‚°ã‚¤ãƒ³å±¥æ­´
def append_login_history(email, result, store_name="", ip_address="ä¸æ˜"):
    file_path = "login_history.csv"
    file_exists = os.path.isfile(file_path)
    with open(file_path, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow(["æ—¥æ™‚", "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", "åº—èˆ—å", "çµæœ", "IPã‚¢ãƒ‰ãƒ¬ã‚¹"])
        writer.writerow([
            datetime.now().isoformat(),
            email,
            store_name,
            result,
            ip_address
        ])





# --- PoCç”¨ ç°¡æ˜“ãƒ­ã‚°ã‚¤ãƒ³ï¼ˆtest@example.com ã®ã¿è¨±å¯ï¼‰ ---
import streamlit as st

# ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸæ™‚ï¼ˆèªè¨¼æˆåŠŸæ™‚ï¼‰
def is_admin():
    return st.session_state.get("username") == "kokoronohitomi2003@keio.jp"







# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³èªè¨¼ç®¡ç† ---
if "login_failures" not in st.session_state:
    st.session_state.login_failures = 0

if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

# --- ãƒ­ã‚°ã‚¤ãƒ³ãƒ­ãƒƒã‚¯ä¸­ã‹ã©ã†ã‹åˆ¤å®š ---
if not st.session_state.authenticated:
    locked_until = st.session_state.get("login_locked_until")
    now = datetime.now()

    if locked_until and now < locked_until:
        remaining = int((locked_until - now).total_seconds())

        st.warning(f"ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—ãŒç¶šã„ã¦ã„ã¾ã™ã€‚ã‚ã¨ {remaining} ç§’å¾Œã«å†å…¥åŠ›ã§ãã¾ã™ã€‚")

        # ã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³è¡¨ç¤ºï¼ˆçœç•¥å¯ï¼šä¸Šè¨˜ã§æ¸ˆã‚€å ´åˆï¼‰
        import streamlit.components.v1 as components
        html_code = f"""
        <div style="text-align:center; font-size:24px; color:#cc8800;">
          <p id="cd_msg">ã‚ã¨ {remaining} ç§’ã§å†å…¥åŠ›ã§ãã¾ã™</p>
        </div>
        <script>
          let sec = {remaining};
          const msg = document.getElementById("cd_msg");
          const interval = setInterval(() => {{
            sec--;
            if (sec <= 0) {{
              location.reload();  // è‡ªå‹•ãƒªãƒ­ãƒ¼ãƒ‰ã§ãƒ•ã‚©ãƒ¼ãƒ å¾©æ´»
              clearInterval(interval);
            }} else {{
              msg.textContent = `ã‚ã¨ ${{
                sec
              }} ç§’ã§å†å…¥åŠ›ã§ãã¾ã™`;
            }}
          }}, 1000);
        </script>
        """
        components.html(html_code, height=100)
        st.stop() 



    col1, col2 = st.columns([1, 5])
    with col1:
        st.image("miral.png", width=240)
    st.title("MIRALãƒ­ã‚°ã‚¤ãƒ³ã¸ã‚ˆã†ã“ã")
    email = st.text_input("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹")
    password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
        user = USER_DB.get(email)
        if user and bcrypt.checkpw(password.encode(), user["password_hash"].encode()):
            st.session_state.authenticated = True
            ip_address = get_client_ip()
            append_login_history(email, "æˆåŠŸ", user["store_name"], ip_address)
            st.session_state.store_name = user["store_name"]
            st.session_state.username = email  
            st.session_state.just_logged_in = True
            st.session_state.login_failures = 0
            st.success("ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ")
            st.rerun()
        else:
            st.session_state.login_failures += 1
            append_login_history(email, "å¤±æ•—", ip_address=ip_address)

            if st.session_state.login_failures >= 3:
                st.session_state.login_locked_until = datetime.now() + timedelta(seconds=10)  

                wait_sec = 10 * (st.session_state.login_failures - 2)
                st.warning(f"ãƒ­ã‚°ã‚¤ãƒ³è©¦è¡ŒãŒè¤‡æ•°å›å¤±æ•—ã—ã¦ã„ã¾ã™ã€‚{wait_sec}ç§’å¾…æ©Ÿä¸­...")

                import streamlit.components.v1 as components
                html_code = f"""
                <div style="text-align:center; font-size:24px; color:#ffcc00; margin-top:20px;">
                <p id="cd_msg">ã‚ã¨ {wait_sec} ç§’ã§å†å…¥åŠ›å¯èƒ½ã§ã™</p>
                </div>
                <script>
                let sec = {wait_sec};
                const msg = document.getElementById("cd_msg");
                const interval = setInterval(() => {{
                    sec--;
                    if (sec <= 0) {{
                    msg.textContent = "å†å…¥åŠ›ã§ãã¾ã™";
                    clearInterval(interval);
                    }} else {{
                    msg.textContent = `ã‚ã¨ ${{
                        sec
                    }} ç§’ã§å†å…¥åŠ›å¯èƒ½ã§ã™`;
                    }}
                }}, 1000);
                </script>
                """
                components.html(html_code, height=100)
                import time
                time.sleep(wait_sec)


        st.error("ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—ï¼šãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")

    st.markdown("""
    <div style='margin-top: 40px; padding: 16px; background-color: #f9f9f9; border-radius: 8px;'>
        <p style='font-size: 14px; color: #333;'>
            ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ MIRAL ãŒé–‹ç™ºã—ãŸæ¥­å‹™æ”¯æ´ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ã™ã€‚<br>
            ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿è­·ã•ã‚ŒãŸç’°å¢ƒã§é‹ç”¨ã•ã‚Œã¦ãŠã‚Šã€ç™»éŒ²ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã¿ãŒã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã§ã™ã€‚
        </p>
        <p style='font-size: 12px; color: #888;'>
            ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ã‚’ãŠæŒã¡ã§ãªã„æ–¹ã¯ã€æ‹…å½“è€…ã¾ã§ã”é€£çµ¡ãã ã•ã„ã€‚
        </p>
        <p style='font-size: 12px; color: #666; margin-top: 12px;'>
            ã“ã®ã‚µã‚¤ãƒˆã¯SSL/TLSã«ã‚ˆã‚Šæš—å·åŒ–ã•ã‚Œã€å®‰å…¨ã«é€šä¿¡ã•ã‚Œã¦ã„ã¾ã™ã€‚
        </p>
        <p style='font-size: 13px; margin-top: 20px;'>
            ãƒ­ã‚°ã‚¤ãƒ³ã«é–¢ã™ã‚‹ãŠå•ã„åˆã‚ã›ã¯ <a href="mailto:aspira.information@gmail.com">aspira.information@gmail.com</a> ã¾ã§ã”é€£çµ¡ãã ã•ã„ã€‚
        </p>
        <p style='font-size: 12px; color: #888;'>
            ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã§ã®ã”åˆ©ç”¨ã¯æ¨ªå‘ãè¡¨ç¤ºã‚’æ¨å¥¨ã—ã¦ã„ã¾ã™ã€‚
        </p>
    </div>
    """, unsafe_allow_html=True)
    st.markdown("""
    <p style='text-align:center; font-size:12px;'>
<a href='https://okikazuyaaa.github.io/miral-policy/privacy.html' target='_blank'>ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼</a> ãƒ»
<a href='https://okikazuyaaa.github.io/miral-policy/terms.html' target='_blank'>åˆ©ç”¨è¦ç´„</a>
</p>
    """, unsafe_allow_html=True)

    st.stop()


# --- ãƒ­ã‚°ã‚¤ãƒ³å¾Œã®å‡¦ç† ---ç®¡ç†è€…ç¢ºèªç”¨-------
if (
    "authenticated" in st.session_state
    and st.session_state.authenticated
    and st.session_state.username == "kokoronohitomi2003@keio.jp"  # ç®¡ç†è€…ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹
):
    if st.button("ãƒ­ã‚°ã‚¤ãƒ³å±¥æ­´ã‚’è¦‹ã‚‹ï¼ˆç®¡ç†è€…ã®ã¿ï¼‰"):
        try:
            with open("login_history.csv", "r", encoding="utf-8") as f:
                lines = f.readlines()

            # åˆ—æ•°ç¢ºèªã—ã¦è£œæ­£
            data = []
            for line in lines:
                parts = line.strip().split(",")
                if len(parts) == 4:
                    parts.append("æœªè¨˜éŒ²")  # IPã‚¢ãƒ‰ãƒ¬ã‚¹åˆ—ã‚’è£œå®Œ
                data.append(parts)

            import pandas as pd
            df = pd.DataFrame(data[1:], columns=["æ—¥æ™‚", "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", "åº—èˆ—å", "çµæœ", "IPã‚¢ãƒ‰ãƒ¬ã‚¹"])

            st.dataframe(df.sort_values("æ—¥æ™‚", ascending=False))

        except Exception as e:
            st.error(f"ãƒ­ã‚°èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")







# ã‚ˆã†ã“ãæ¼”å‡ºï¼ˆãƒ­ã‚°ã‚¤ãƒ³ç›´å¾Œ1å›ã ã‘ï¼‰
if st.session_state.get("just_logged_in", False):
    with open("haikei.jpeg", "rb") as f:
        bg_data = base64.b64encode(f.read()).decode()

    html_code = f"""
    <html>
    <head>
      <style>
        body {{
          margin: 0;
          padding: 0;
          font-family: 'Segoe UI', sans-serif;
          background: url("data:image/jpeg;base64,{bg_data}") no-repeat center center fixed;
          background-size: cover;
          height: 100vh;
          display: flex;
          justify-content: center;
          align-items: center;
          color: white;
        }}
        .overlay {{
          background: rgba(0, 0, 0, 0.5);
          padding: 60px 40px;
          border-radius: 20px;
          box-shadow: 0 8px 20px rgba(0,0,0,0.3);
          text-align: center;
        }}
        h1 {{
          font-size: 40px;
          margin: 0;
        }}
        p {{
          font-size: 20px;
          margin-top: 10px;
        }}
      </style>
    </head>
    <body>
      <div class="overlay">
        <h1>ã‚ˆã†ã“ãã€{st.session_state.get('store_name', 'MIRAL')}æ§˜</h1>
        <p>ãƒ­ã‚°ã‚¤ãƒ³ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™</p>
      </div>
    </body>
    </html>
    """

    components.html(html_code, height=600)
    time.sleep(3.5)
    st.session_state.just_logged_in = False
    st.rerun()


# ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆã™ã§ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã® .cbmï¼‰
#model = CatBoostRegressor()
#model.load_model("model_catboost.cbm")

# pklå½¢å¼ã§ä¿å­˜
#joblib.dump(model, "model_weather.pkl")  # â† å…ƒã®XGBoostç½®ãæ›ãˆç”¨

# --- åº—èˆ—åã®å–å¾— ---
selected_store = st.session_state.get("store_name")

# --- Excelãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«è¾æ›¸ ---
file_map_excel = {
    "ã‚ªãƒ¼ãƒ‘ã‚¹å®®å´æœ¬åº—": "data/2025_miyazaki.xlsx",
    "ã‚ªãƒ¼ãƒ‘ã‚¹å°æ¾": "data/2025_komatsu.xlsx",
    "ã‚ªãƒ¼ãƒ‘ã‚¹é«˜é‹": "data/2025_takanabe.xlsx",
    "ã‚ªãƒ¼ãƒ‘ã‚¹æ—¥å—": "data/2025_nichinan.xlsx",
    "ã‚ªãƒ¼ãƒ‘ã‚¹å»¶å²¡": "data/2025_nobeoka.xlsx",
    "ã‚ªãƒ¼ãƒ‘ã‚¹ä¸‰è‚¡": "data/2025_mimata.xlsx",
    "ã‚ªãƒ¼ãƒ‘ã‚¹éƒ½åŸ": "data/2025_miyakonojo.xlsx",
    "ã‚ªãƒ¼ãƒ‘ã‚¹é¹¿å±‹": "data/2025_kanoya.xlsx",
}

file_map_models = {
    "ã‚ªãƒ¼ãƒ‘ã‚¹å®®å´æœ¬åº—": {
        "weather": "models/miyazaki/model_weather.pkl",
        "sales": "models/miyazaki/model_sales.pkl",
        "profit": "models/miyazaki/model_profit.pkl",
        "hit": "models/miyazaki/model_hit.pkl",
        "base": "models/miyazaki/model.pkl"
    },
    "ã‚ªãƒ¼ãƒ‘ã‚¹å°æ¾": {
        "weather": "models/komatsu/model_weather.pkl",
        "sales": "models/komatsu/model_sales.pkl",
        "profit": "models/komatsu/model_profit.pkl",
        "hit": "models/komatsu/model_hit.pkl",
        "base": "models/komatsu/model.pkl"
    },
    "ã‚ªãƒ¼ãƒ‘ã‚¹é«˜é‹": {
        "weather": "models/takanabe/model_weather.pkl",
        "sales": "models/takanabe/model_sales.pkl",
        "profit": "models/takanabe/model_profit.pkl",
        "hit": "models/takanabe/model_hit.pkl",
        "base": "models/takanabe/model.pkl"
    },
    "ã‚ªãƒ¼ãƒ‘ã‚¹æ—¥å—": {
        "weather": "models/nichinan/model_weather.pkl",
        "sales": "models/nichinan/model_sales.pkl",
        "profit": "models/nichinan/model_profit.pkl",
        "hit": "models/nichinan/model_hit.pkl",
        "base": "models/nichinan/model.pkl"
    },
    "ã‚ªãƒ¼ãƒ‘ã‚¹å»¶å²¡": {
        "weather": "models/nobeoka/model_weather.pkl",
        "sales": "models/nobeoka/model_sales.pkl",
        "profit": "models/nobeoka/model_profit.pkl",
        "hit": "models/nobeoka/model_hit.pkl",
        "base": "models/nobeoka/model.pkl"
    },
    "ã‚ªãƒ¼ãƒ‘ã‚¹ä¸‰è‚¡": {
        "weather": "models/mimata/model_weather.pkl",
        "sales": "models/mimata/model_sales.pkl",
        "profit": "models/mimata/model_profit.pkl",
        "hit": "models/mimata/model_hit.pkl",
        "base": "models/mimata/model.pkl"
    },
    "ã‚ªãƒ¼ãƒ‘ã‚¹éƒ½åŸ": {
        "weather": "models/miyakonojo/model_weather.pkl",
        "sales": "models/miyakonojo/model_sales.pkl",
        "profit": "models/miyakonojo/model_profit.pkl",
        "hit": "models/miyakonojo/model_hit.pkl",
        "base": "models/miyakonojo/model.pkl"
    },
    "ã‚ªãƒ¼ãƒ‘ã‚¹é¹¿å±‹": {
        "weather": "models/kanoya/model_weather.pkl",
        "sales": "models/kanoya/model_sales.pkl",
        "profit": "models/kanoya/model_profit.pkl",
        "hit": "models/kanoya/model_hit.pkl",
        "base": "models/kanoya/model.pkl"
    },
}
# # --- ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿é–¢æ•° _
def load_csv(path, **kwargs):
    if not os.path.exists(path):
        st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}")
        st.stop()
    return pd.read_csv(path, **kwargs)

def load_excel_store_filtered(path, **kwargs):
    if not os.path.exists(path):
        st.error("è©²å½“ã™ã‚‹åº—èˆ—ã®åˆ†æãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ç®¡ç†è€…ã«ã”é€£çµ¡ãã ã•ã„ã€‚")
        st.stop()
    xls = pd.ExcelFile(path)
    df = pd.concat([xls.parse(sheet).assign(å¯¾è±¡ã‚·ãƒ¼ãƒˆ=sheet) for sheet in xls.sheet_names], ignore_index=True)
    df.columns = df.columns.astype(str).str.strip()
    return df

def load_pkl(path):
    if not os.path.exists(path):
        st.error(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}")
        st.stop()
    return joblib.load(path)

# --- å…±é€šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆãƒšãƒ¼ã‚¸ä¸Šã§ä½¿ç”¨ï¼‰ ---
mapped_store = store_name_map.get(store_name, store_name)
selected_excel = file_map_excel.get(mapped_store)

if not selected_excel or not os.path.exists(selected_excel):
    st.warning("ã“ã®åº—èˆ—ã«ã¯åˆ†æãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ä¸€éƒ¨ã®ãƒšãƒ¼ã‚¸ã§ã¯å†…å®¹ãŒè¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ã€‚")
    df_merged = pd.DataFrame()  # ç©ºã®DataFrameã‚’ä»£ã‚ã‚Šã«å…¥ã‚Œã‚‹
else:
    df_merged = load_excel_store_filtered(selected_excel)


# ------------------------------
# âœ… 4. å¯¾å¿œãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«ä½¿ç”¨
# ------------------------------
model_paths = file_map_models[mapped_store]


model_paths = file_map_models[selected_store]
model = load_pkl(model_paths["weather"])
model_sales = load_pkl(model_paths["sales"])
model_profit = load_pkl(model_paths["profit"])
model_hit = load_pkl(model_paths["hit"])
model_base = load_pkl(model_paths["base"])






if selected_store != "ç®¡ç†è€…":
    try:
        selected_excel = file_map_excel[selected_store]
    except KeyError:
        st.warning(f"åº—èˆ—ã€Œ{selected_store}ã€ã«å¯¾å¿œã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
else:
    st.info("ç®¡ç†è€…ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§ã¯åˆ†æãƒ•ã‚¡ã‚¤ãƒ«ã®é¸æŠã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")



# --- ãƒ‘ã‚¹å‹•çš„ç”Ÿæˆé–¢æ•° ---
def get_store_file(filename_template):
    fallback_path = f"data/{filename_template}"  # å…±é€šãƒ•ã‚¡ã‚¤ãƒ«
    store_path = f"data/{selected_store}_{filename_template}"  # åº—èˆ—ãƒ•ã‚¡ã‚¤ãƒ«
    return store_path if os.path.exists(store_path) else fallback_path





# ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒ¡ãƒ‹ãƒ¥ãƒ¼

st.title("å£²ä¸ŠAIåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
#store_name = st.session_state.get("store_name", "åº—èˆ—åæœªè¨­å®š")
# --- ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸè‹±èªåã®å–å¾— ---
mapped_store = store_name_map.get(store_name)
#st.markdown(f"### ğŸ¢ ç¾åœ¨ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã®åº—èˆ—ï¼š**{store_name}**")



# --- ãƒšãƒ¼ã‚¸ä¸€è¦§ã¨åˆæœŸé¸æŠ ---
pages = {
    "è‡ªç¤¾ãƒ›ãƒ¼ãƒ«ã®åˆ†æ": "è‡ªç¤¾ãƒ›ãƒ¼ãƒ«ã®åˆ†æ",
    # "æœˆåˆ¥å£²ä¸Šç›®æ¨™ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰": "æœˆåˆ¥å£²ä¸Šç›®æ¨™ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    # "å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼": "å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼",
    # "å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼ˆæœ€é©åŒ–ï¼‰": "å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼ˆæœ€é©åŒ–ï¼‰",
    "å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼vol.2": "å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼vol.2",
    "å¤©å€™ä»˜ãå£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼": "å¤©å€™ä»˜ãå£²ä¸Šäºˆæ¸¬",
    "What-ifã‚·ãƒŠãƒªã‚ªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼": "What-ifåˆ†æ",
    "æ™‚é–“å¸¯åˆ¥å®¢æ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—": "æ™‚é–“å¸¯åˆ¥å®¢æ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
    "æ™‚é–“å¸¯åˆ¥å£²ä¸ŠåŠ¹ç‡åˆ†æ": "å£²ä¸ŠåŠ¹ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
    "æ©Ÿç¨®åˆ¥å„Ÿå´åŠ¹ç‡åˆ†æ": "æ©Ÿç¨®åˆ¥åˆ†æ",
    "åœ°ç†ãƒãƒƒãƒ—åˆ†æ": "åœ°ç†ãƒãƒƒãƒ—",
    "ãƒ›ãƒ¼ãƒ«å†…ãƒ©ãƒ³ã‚­ãƒ³ã‚°": "ãƒ›ãƒ¼ãƒ«å†…ãƒ©ãƒ³ã‚­ãƒ³ã‚°",
    "ã‚¤ãƒ™ãƒ³ãƒˆå½±éŸ¿åˆ†æ": "ã‚¤ãƒ™ãƒ³ãƒˆå½±éŸ¿åˆ†æ",
    "AIã‚³ãƒ³ã‚µãƒ«ã‚¢ãƒ‰ãƒã‚¤ã‚¹": "AIã‚³ãƒ³ã‚µãƒ«"
}

if "selected_page" not in st.session_state:
    st.session_state.selected_page = list(pages.keys())[0]

# --- ãƒ¡ãƒ‹ãƒ¥ãƒ¼è¡¨ç¤ºï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰ ---
st.sidebar.markdown("### ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
for page_name, label in pages.items():
    selected = st.session_state.selected_page == page_name
    if selected:
        st.sidebar.markdown(f"""
        <div style="
            display: block;
            width: 100%;
            text-align: left;
            background-color: rgba(255,255,255,0.35);
            border: 1px solid rgba(255,255,255,0.25);
            border-left: 6px solid #a88838;
            border-radius: 14px;
            padding: 16px 24px;
            margin-bottom: 12px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.08);
            font-weight: bold;
            font-size: 16px;
            color: #2f2f2f;
        ">{label}</div>""", unsafe_allow_html=True)
    else:
        if st.sidebar.button(label, key=f"menu_{page_name}"):
            st.session_state.selected_page = page_name
            st.rerun()


#ãƒ­ã‚°ã‚¢ã‚¦ãƒˆå‡¦ç†
with st.sidebar:
    st.markdown("---")
    if st.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()



# ãƒšãƒ¼ã‚¸å…¨ä½“ã‚¹ã‚¿ã‚¤ãƒ«ï¼šèƒŒæ™¯è‰²ï¼‹ãƒ•ã‚©ãƒ³ãƒˆï¼‹åŸºæœ¬ã®è¦‹ãŸç›®ã‚’æ•´ãˆã‚‹
page_style = """
<style>
/* å…¨ä½“èƒŒæ™¯ */
body, .stApp {
    background-color: #f7f5f0 !important;
    color: #2f2f2f;
    font-family: 'Yu Mincho', serif;
}


/* è¦‹å‡ºã—è£…é£¾ */
h1, h2, h3, h4 {
    font-family: 'Yu Mincho', serif;
    color: #1e1e1e;
}


/* ã‚«ãƒ¼ãƒ‰ã£ã½ã„è¦ç´  */
div[data-testid="stMetric"] {
    background-color: #ffffffdd;
    padding: 10px;
    border-radius: 12px;
    box-shadow: 0 3px 8px rgba(0, 0, 0, 0.06);
    margin-bottom: 8px;
}
</style>
"""
st.markdown(page_style, unsafe_allow_html=True)

# ğŸ”½ ã“ã“ã«è¿½åŠ 
def generate_advice(æ©Ÿç¨®å, å„Ÿå´åŠ¹ç‡, ç²—åˆ©, å„Ÿå´é¡):
    import random
    if å„Ÿå´åŠ¹ç‡ > 3000:
        opening = random.choice([
            f"ã€Œ{æ©Ÿç¨®å}ã€ã¯ã€ç¾çŠ¶ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¦‹ã¦éå¸¸ã«å„ªã‚ŒãŸé‹ç”¨æˆæœã‚’ä¸Šã’ã¦ãŠã‚Šã€ä»Šå¾Œã®ä¸­æ ¸æ©Ÿç¨®å€™è£œã¨ã„ãˆã¾ã™ã€‚",
            f"ã€Œ{æ©Ÿç¨®å}ã€ã¯ã€ç¾å ´ã«ãŠã„ã¦æ³¨ç›®ã™ã¹ãé«˜åŠ¹ç‡æ©Ÿç¨®ã§ã™ã€‚"
        ])
        detail = random.choice([
            f"1æ—¥ã‚ãŸã‚Šã®ç²—åˆ©ãŒ {ç²—åˆ©:,.0f} å††ã«å¯¾ã—ã€æ—¥å„Ÿå´é¡ã¯ {å„Ÿå´é¡:,.0f} å††ã€‚å·®ã—å¼•ãã§ +{å„Ÿå´åŠ¹ç‡:,.0f} å††ã®åç›Šæ€§ã‚’ç¢ºä¿ã—ã¦ã„ã¾ã™ã€‚",
            f"åæ”¯ãƒãƒ©ãƒ³ã‚¹ã«ãŠã„ã¦å®‰å®šæ„ŸãŒã‚ã‚Šã€ç¾æ™‚ç‚¹ã§ã‚‚ååˆ†ãªåˆ©ç›Šæºã¨ã—ã¦æ©Ÿèƒ½ã—ã¦ã„ã¾ã™ã€‚"
        ])
        suggestion = random.choice([
            "å¢—å°ã‚„ã‚¤ãƒ™ãƒ³ãƒˆã§ã®å„ªé‡é…ç½®ã‚’æ¤œè¨ã™ã‚‹ã“ã¨ã§ã€æ›´ãªã‚‹é›†å®¢ãƒ»åç›Šå¢—åŠ ãŒè¦‹è¾¼ã‚ã¾ã™ã€‚",
            "é‹ç”¨æˆ¦ç•¥ã®æŸ±ã¨ã—ã¦ã€ã‚ˆã‚Šé•·æœŸçš„ãªæ´»ç”¨ã‚‚é¸æŠè‚¢ã«å…¥ã‚‹ã§ã—ã‚‡ã†ã€‚",
            "ã‚ˆã‚Šç©æ¥µçš„ãªè¨´æ±‚ãƒ»ç¨¼åƒå¼·åŒ–ã‚’æ¤œè¨ã™ã‚‹ãƒ•ã‚§ãƒ¼ã‚ºã«ã‚ã‚Šã¾ã™ã€‚"
        ])
        return f"{opening}\n{detail}\n{suggestion}"

    elif å„Ÿå´åŠ¹ç‡ < 0:
        opening = random.choice([
            f"ã€Œ{æ©Ÿç¨®å}ã€ã«ã¤ã„ã¦ã¯ã€ç¾åœ¨ã®å„Ÿå´ãƒãƒ©ãƒ³ã‚¹ã«èª²é¡ŒãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚",
            f"ã€Œ{æ©Ÿç¨®å}ã€ã¯ã€åç›Šæ€§ã«ãŠã„ã¦ã‚„ã‚„ä¸å®‰å®šãªçŠ¶æ³ã«ã‚ã‚Šã¾ã™ã€‚"
        ])
        detail = random.choice([
            f"ç²—åˆ© {ç²—åˆ©:,.0f} å††ã«å¯¾ã—ã€å„Ÿå´é¡ {å„Ÿå´é¡:,.0f} å††ã‚’ä¸‹å›ã£ã¦ãŠã‚Šã€å·®é¡ã¯ {å„Ÿå´åŠ¹ç‡:,.0f} å††ã®ãƒã‚¤ãƒŠã‚¹ã§ã™ã€‚",
            f"ç¾è¡Œã®é‹ç”¨ã‚¹ã‚¿ã‚¤ãƒ«ã§ã¯ã€ç¶™ç¶šçš„ãªèµ¤å­—çŠ¶æ…‹ãŒæƒ³å®šã•ã‚Œã¾ã™ã€‚"
        ])
        suggestion = random.choice([
            "æ—©æœŸã®æ’¤å»ã‚„æ§‹æˆè¦‹ç›´ã—ã‚’å«ã‚ãŸå†æ¤œè¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚",
            "ç¨¼åƒãŒä¼´ã‚ãªã„å ´åˆã€æ©Ÿç¨®ã®ãƒªã‚¹ãƒˆãƒ©ã‚‚å«ã‚ãŸåˆ¤æ–­ãŒæ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚",
            "æ©Ÿç¨®æ§‹æˆã®ã‚¹ãƒªãƒ åŒ–ã‚„ã€ä»–æ©Ÿç¨®ã¸ã®æŠ•è³‡è»¢æ›ã‚’è¦–é‡ã«å…¥ã‚Œã‚‹ã¹ãã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚"
        ])
        return f"{opening}\n{detail}\n{suggestion}"

    else:
        return ""
    

# --- è‡ªç¤¾ãƒ›ãƒ¼ãƒ«ã®åˆ†æãƒšãƒ¼ã‚¸ç”¨CSVã‚’å‹•çš„ã«èª­ã¿è¾¼ã¿ ---
df_store = load_csv(get_store_file("5pachi_geocode.csv"), encoding="shift_jis")
df_town = load_csv(get_store_file("miyazaki_city_with_latlon.csv"), encoding="utf-8")
#df_town = load_csv(get_store_file("city_with_latlon.csv"), encoding="utf-8")
#df_sales = load_csv(get_store_file("sales_weather.csv"), encoding="utf-8", parse_dates=["æ—¥ä»˜"])
#df_customers = load_csv(get_store_file("hourly_customers.csv"), encoding="utf-8-sig", parse_dates=["æ—¥ä»˜"])



# --- å„ãƒšãƒ¼ã‚¸ã®å†…å®¹ ---
# ãƒšãƒ¼ã‚¸1ï¼šè‡ªç¤¾ãƒ›ãƒ¼ãƒ«ã®åˆ†æ
if st.session_state.selected_page == "è‡ªç¤¾ãƒ›ãƒ¼ãƒ«ã®åˆ†æ":
    #store_name = st.session_state.get("store_name", "åº—èˆ—åæœªè¨­å®š")
    st.markdown(f"### ğŸ¢ ç¾åœ¨ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã®åº—èˆ—ï¼š**{store_name}**")
    st.title("ğŸª è‡ªç¤¾ãƒ›ãƒ¼ãƒ«ã®åˆ†æ")
    st.write("ã“ã“ã«è‡ªç¤¾ãƒ›ãƒ¼ãƒ«ã®çµ±è¨ˆæƒ…å ±ãªã©ã‚’è¡¨ç¤º")


    # ----------------------
    # åº—èˆ—ï¼ˆé¡§å®¢å°‚ç”¨ï¼‰
    filtered_store = df_store[df_store["ãƒ›ãƒ¼ãƒ«å"] == selected_store]
    if filtered_store.empty:
        st.error(f"âŒ ã€Œ{selected_store}ã€ã¯ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        st.stop()
    store_data = filtered_store.iloc[0]
    store_lat, store_lon = store_data["ç·¯åº¦"], store_data["çµŒåº¦"]
    P = store_data["På°æ•°"]
    S = store_data["Så°æ•°"]
    total = P + S


    # ----------------------
    # åº—èˆ—ãƒ©ãƒ³ã‚¯ï¼ˆä»®ãƒ«ãƒ¼ãƒ«ï¼‰
    if total >= 600:
        rank = "å¤§å‹"
    elif total >= 400:
        rank = "ä¸­å‹"
    else:
        rank = "å°å‹"


    # ----------------------
    # å•†åœäººå£ï¼ˆç·¯åº¦çµŒåº¦ã‹ã‚‰åŠå¾„5kmåœå†…ï¼‰
    df_town = pd.read_csv("./data/miyazaki_city_with_latlon.csv", encoding="utf-8")
    def haversine(lat1, lon1, lat2, lon2):
        R = 6371
        phi1, phi2 = map(math.radians, (lat1, lat2))
        dphi = math.radians(lat2 - lat1)
        dlmb = math.radians(lon2 - lon1)
        a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlmb/2)**2
        return 2 * R * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    df_town["dist_km"] = df_town.apply(lambda x: haversine(store_lat, store_lon, x["latitude"], x["longitude"]), axis=1)
    area_population = 0.1*(df_town[df_town["dist_km"] <= 5]["population"].sum())  # 5kmåœ


    # ----------------------
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³â‘ ï¼šã‚µãƒãƒªãƒ¼ã‚«ãƒ¼ãƒ‰
    st.markdown("## ã‚ãªãŸã®ãƒ›ãƒ¼ãƒ«ã®æ¦‚è¦", unsafe_allow_html=True)
    col1, col2, col3, col4 = st.columns(4)
    col1.metric(" På°æ•°", P)
    col2.metric(" Så°æ•°", S)
    col3.metric(" åº—èˆ—ãƒ©ãƒ³ã‚¯", rank)
    col4.metric(" å•†åœäººå£ï¼ˆ5kmåœï¼‰", f"{int(area_population):,}äºº")


    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³â‘ .5ï¼šæ§‹æˆæ¯”ã‚°ãƒ©ãƒ•ï¼ˆPå°æ•° vs Så°æ•°ï¼‰
    st.markdown("##  éŠæŠ€æ©Ÿæ§‹æˆãƒãƒ©ãƒ³ã‚¹", unsafe_allow_html=True)


    df = pd.DataFrame({
        "é …ç›®": ["På°æ•°", "Så°æ•°"],
        "å€¤": [P, S]
    })


    chart = alt.Chart(df).mark_bar(
        color='#a88838',
        cornerRadiusTopLeft=4,
        cornerRadiusTopRight=4
    ).encode(
        x=alt.X("é …ç›®:N", axis=alt.Axis(labelColor='#2f2f2f', title='')),
        y=alt.Y("å€¤:Q", axis=alt.Axis(labelColor='#2f2f2f', title='å°æ•°')),
        tooltip=["é …ç›®", "å€¤"]
    ).properties(
        width=400,
        height=300,
        background='#f7f5f0',
        title="P / S å°æ•°æ§‹æˆ"
    ).configure_title(
        font='Yu Mincho',
        fontSize=18,
        color='#333'
    ).configure_view(
        stroke=None  # å¤–æ ã‚’ãªãã—ã¦æŸ”ã‚‰ã‹ã
    )


    st.altair_chart(chart, use_container_width=False)




    # ----------------------
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³â‘¡ï¼šè‡ªåº—ã¨ç«¶åˆã®ãƒãƒ–ãƒ«ãƒãƒƒãƒ—
    st.markdown("## åº—èˆ—é…ç½®ã¨å‘¨è¾ºç«¶åˆ")
    import folium
    from streamlit_folium import folium_static
    m = folium.Map(location=[store_lat, store_lon], zoom_start=13)
    folium.CircleMarker(location=[store_lat, store_lon], radius=12, color="red", fill=True, tooltip="ã‚ãªãŸã®åº—èˆ—").add_to(m)
    for _, row in df_store.iterrows():
        if row["ãƒ›ãƒ¼ãƒ«å"] != selected_store:
            folium.CircleMarker(location=[row["ç·¯åº¦"], row["çµŒåº¦"]], radius=8, color="blue", fill=True, tooltip=row["ãƒ›ãƒ¼ãƒ«å"]).add_to(m)
    folium_static(m)


    # ----------------------
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³â‘£ï¼šå•†åœã‚·ã‚§ã‚¢ï¼ˆHuffï¼‰
    st.markdown("##  å•†åœã‚·ã‚§ã‚¢ç‡")
    alpha = 1.5
    time_factors = {8: 0.7, 12: 0.93, 18: 0.8}
    weather_factor = 0.8
    hour = 12
    pop_factor = time_factors[hour] * weather_factor
    pop_dyn = df_town["population"] * pop_factor
    pop_sum = pop_dyn.sum()


    shares = []
    for store in df_store.itertuples():
        dists = df_town.apply(lambda t: haversine(t["latitude"], t["longitude"], store.ç·¯åº¦, store.çµŒåº¦) + 1e-6, axis=1)
        weights = (store.På°æ•° + store.Så°æ•°) / (dists ** alpha)
        pij = weights / weights.sum()
        share = (pop_dyn * pij).sum() / pop_sum
        shares.append(share)
    df_store["share"] = shares
    target_share = df_store[df_store["ãƒ›ãƒ¼ãƒ«å"] == selected_store]["share"].values[0]

        # --- â˜…å¹³å‡å£²ä¸Šå˜ä¾¡ã®ç®—å‡ºï¼ˆmerged_sales_weather + hourly_customers_longï¼‰
    try:
        df_sales = pd.read_csv(get_store_file("merged_sales_weather.csv"), encoding="utf-8", parse_dates=["æ—¥ä»˜"])
        df_customers = pd.read_csv(get_store_file("hourly_customers_long.csv"), encoding="utf-8-sig", parse_dates=["æ—¥ä»˜"])
        df_total = df_customers.groupby("æ—¥ä»˜")["å®¢æ•°"].sum().reset_index()
        if df_merged.empty:
            st.warning("ã“ã®åº—èˆ—ã«ã¯å¯¾å¿œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€ã“ã®ãƒšãƒ¼ã‚¸ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
            st.stop()
        df_merged = pd.merge(df_sales, df_total, on="æ—¥ä»˜", how="inner")
        df_merged["å£²ä¸Šå˜ä¾¡"] = df_merged["å°å£²ä¸Šåˆè¨ˆ"] / df_merged["å®¢æ•°"]
        avg_sales_per_person = df_merged["å£²ä¸Šå˜ä¾¡"].mean()
    except Exception as e:
        st.error("å£²ä¸Šå˜ä¾¡ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã€‚ä»®ã«8000å††ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        avg_sales_per_person = 8000

    st.markdown("###  æ©Ÿç¨®æ§‹æˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    adjusted_P = st.slider("På°æ•°ï¼ˆèª¿æ•´å¾Œï¼‰", 0, 600, value=P, step=10)
    adjusted_S = st.slider("Så°æ•°ï¼ˆèª¿æ•´å¾Œï¼‰", 0, 600, value=S, step=10)

    df_store_sim = df_store.copy()
    df_store_sim.loc[df_store_sim["ãƒ›ãƒ¼ãƒ«å"] == selected_store, "På°æ•°"] = adjusted_P
    df_store_sim.loc[df_store_sim["ãƒ›ãƒ¼ãƒ«å"] == selected_store, "Så°æ•°"] = adjusted_S

    shares_improved = []
    for store in df_store_sim.itertuples():
        dists = df_town.apply(lambda t: haversine(t["latitude"], t["longitude"], store.ç·¯åº¦, store.çµŒåº¦) + 1e-6, axis=1)
        weights = (store.På°æ•° + store.Så°æ•°) / (dists ** alpha)
        pij = weights / weights.sum()
        share = (pop_dyn * pij).sum() / pop_sum
        shares_improved.append(share)
    df_store_sim["share"] = shares_improved
    adjusted_share = df_store_sim[df_store_sim["ãƒ›ãƒ¼ãƒ«å"] == selected_store]["share"].values[0]

    adjusted_value = adjusted_share * 1.25 * 100
    adjusted_delta = adjusted_value - (target_share * 100)
    share_diff = adjusted_delta / 100
    additional_visitors = int(area_population * share_diff)
    revenue_gain = int(additional_visitors * avg_sales_per_person)

    st.markdown("### å•†åœã‚·ã‚§ã‚¢ã¨å£²ä¸Šã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ")
    col1, col2 = st.columns(2)
    col1.metric("ç¾çŠ¶ã‚·ã‚§ã‚¢", f"{target_share*100:.2f}%")
    col2.metric("æ§‹æˆå¤‰æ›´å¾Œã‚·ã‚§ã‚¢", f"{adjusted_value:.2f}%", delta=f"{adjusted_delta:+.2f}%")

    st.markdown("### äºˆæ¸¬ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆæ›ç®—ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼‰")
    st.markdown(f"""
    - **æƒ³å®šè¿½åŠ æ¥åº—è€…æ•°**ï¼š<span style="color:#a88838; font-weight:bold">{additional_visitors:,}äºº</span>  
    - **æƒ³å®šè¿½åŠ å£²ä¸Šï¼ˆ1äººã‚ãŸã‚ŠÂ¥{int(avg_sales_per_person):,}ï¼‰**ï¼š<span style="color:#a88838; font-weight:bold">Â¥{revenue_gain:,}</span>
    """, unsafe_allow_html=True)



    # æ”¹å–„å¾Œã®ã‚·ã‚§ã‚¢å–å¾—
    improved_share = df_store_sim[df_store_sim["ãƒ›ãƒ¼ãƒ«å"] == selected_store]["share"].values[0]




    #  è¡¨ç¤ºãƒ–ãƒ­ãƒƒã‚¯ï¼ˆé«˜ç´šé¢¨ï¼‰
    st.markdown("###  å•†åœã‚·ã‚§ã‚¢æ”¹å–„äºˆæ¸¬", unsafe_allow_html=True)
    col1, col2 = st.columns(2)
    col1.metric("ç¾çŠ¶ã‚·ã‚§ã‚¢", f"{target_share*100:.2f}%")
        # è¡¨ç¤ºç”¨å€¤ï¼ˆ1.25å€è£œæ­£ã—ã¦%è¡¨ç¤ºï¼‰
    adjusted_value = improved_share * 1.25 * 100
    # å·®åˆ†ï¼ˆè£œæ­£å¾Œã®å€¤ã¨ç¾çŠ¶%ã®å·®ï¼‰
    adjusted_delta = adjusted_value - (target_share * 100)


    col2.metric(
        "æ”¹å–„å¾Œäºˆæ¸¬",
        f"{adjusted_value:.2f}%",
        delta=f"{adjusted_delta:+.2f}%",
        delta_color="normal"
)
    #  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä»®ç½®ããƒ»å¾Œã§èª¿æ•´å¯ï¼‰
    avg_sales_per_person = 8000  # 1äººã‚ãŸã‚Šå£²ä¸Š
    population = area_population  # å•†åœäººå£ï¼ˆ5kmåœï¼‰


    #  å·®åˆ†è¨ˆç®—ï¼ˆã™ã§ã«è£œæ­£ã•ã‚ŒãŸ share ã‚’ä½¿ã†ï¼‰
    adjusted_value = improved_share * 1.25 * 100
    adjusted_delta = adjusted_value - (target_share * 100)
    share_diff = (adjusted_delta) / 100  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆè¡¨è¨˜ã‚’å°æ•°ã«æˆ»ã™


    #  æ¥åº—è€…æ•°ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ
    additional_visitors = int(population * share_diff)


    #  å£²ä¸Šã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ
    revenue_gain = int(additional_visitors * avg_sales_per_person)


    #  è¡¨ç¤º
    st.markdown("###  äºˆæ¸¬ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆæ›ç®—", unsafe_allow_html=True)


    st.markdown(f"""
    -  **æƒ³å®šè¿½åŠ æ¥åº—è€…æ•°**ï¼š<span style="color:#a88838; font-weight:bold">{additional_visitors:,}äºº</span>  
    -  **æƒ³å®šè¿½åŠ å£²ä¸Š**ï¼š<span style="color:#a88838; font-weight:bold">Â¥{revenue_gain:,}</span>
    """, unsafe_allow_html=True)


    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³â‘¤ï¼šAIã«ã‚ˆã‚‹è‡ªç„¶æ–‡ææ¡ˆï¼ˆadjustedæ§‹æˆã«å¯¾å¿œï¼‰
    st.markdown("##  AIã‹ã‚‰ã®æ”¹å–„ã‚¢ãƒ‰ãƒã‚¤ã‚¹")

    # åœ°åŸŸå¹³å‡
    avg_P = int(df_store["På°æ•°"].mean())
    avg_S = int(df_store["Så°æ•°"].mean())
    avg_total = int(df_store["På°æ•°"].mean() + df_store["Så°æ•°"].mean())

    # ç¾åœ¨ã®æ§‹æˆï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§èª¿æ•´å¾Œã®å€¤ï¼‰
    total = adjusted_P + adjusted_S

    # â‘  På°æ•°ãŒå°‘ãªã„ â†’ æ‹¡å¼µææ¡ˆ
    if adjusted_P < avg_P - 20:
        st.info(
            f"""
            På°æ•°ãŒåœ°åŸŸå¹³å‡ï¼ˆ{avg_P}å°ï¼‰ã‚ˆã‚Šå°‘ãªãã€é›†å®¢ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’æ´»ã‹ã—ãã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

            **ææ¡ˆ**ï¼šPå°æ•°ã‚’ +20ã€œ+40 å°å¢—ã‚„ã™ã“ã¨ã§ã€Huffãƒ¢ãƒ‡ãƒ«ä¸Šã®æ¥åº—ç¢ºç‡ãŒä¸Šæ˜‡ã—ã€å•†åœã‚·ã‚§ã‚¢ãŒæ‹¡å¤§ã™ã‚‹ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚
            """
        )

    # â‘¡ Så°æ•°ãŒå¤šã„ â†’ æ©Ÿæ§‹æˆæœ€é©åŒ–ææ¡ˆ
    elif adjusted_S > avg_S + 20:
        st.warning(
            f"""
            Så°æ•°ãŒåœ°åŸŸå¹³å‡ï¼ˆ{avg_S}å°ï¼‰ã‚ˆã‚Šå¤šãã€ç¨¼åƒç‡ãŒä½ä¸‹ã—ã¦ã„ã‚‹æã‚ŒãŒã‚ã‚Šã¾ã™ã€‚

            **ææ¡ˆ**ï¼šSå°æ•°ã‚’ -30ã€œ-50 å°èª¿æ•´ã—ã€äººæ°—æ©Ÿç¨®ä¸­å¿ƒã®ãƒ©ã‚¤ãƒ³ãƒŠãƒƒãƒ—ã«æœ€é©åŒ–ã™ã‚‹ã“ã¨ã§ã€1å°ã‚ãŸã‚Šã®å£²ä¸ŠåŠ¹ç‡ãŒå‘ä¸Šã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
            """
        )

    # â‘¢ P+S ãŒå¹³å‡ã‚ˆã‚Šå°ã•ã„ â†’ æ‹¡å¼µï¼‹åºƒå‘Šææ¡ˆ
    elif total < avg_total - 50:
        st.info(
            f"""
            ç·è¨­ç½®å°æ•°ï¼ˆ{total}å°ï¼‰ãŒåœ°åŸŸå¹³å‡ï¼ˆ{avg_total}å°ï¼‰ã‚ˆã‚Šå°‘ãªãã€å•†åœå†…ã§ã®å­˜åœ¨æ„ŸãŒå¼±ã¾ã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

            **ææ¡ˆ**ï¼šä¸€éƒ¨ãƒ•ãƒ­ã‚¢æ‹¡å¼µ or å¼·åŒ–è¨´æ±‚ï¼ˆæŠ˜è¾¼ãƒ»LINEï¼‰ã«ã‚ˆã‚Šæ¥åº—æ•°ã®åº•ä¸Šã’ã‚’ç‹™ãˆã¾ã™ã€‚
            """
        )

    # â‘£ è¦æ¨¡ã¯å¤§ãã„ãŒSåé‡ â†’ãƒãƒ©ãƒ³ã‚¹æ˜¯æ­£ææ¡ˆ
    elif adjusted_P > 400 and adjusted_S > 250:
        st.warning(
            f"""
            âš ï¸ Pã¨SãŒã¨ã‚‚ã«å¤šãã€ç‰¹ã«Sæ§‹æˆãŒã‚„ã‚„éå‰°ãªå‚¾å‘ã§ã™ã€‚

            **ææ¡ˆ**ï¼šSå°æ•°ã‚’ -10ã€œ-20å°èª¿æ•´ã—ã€På°å„ªé‡å‹æ§‹æˆã«å¯„ã›ã‚‹ã¨ã€ãƒ”ãƒ¼ã‚¯æ™‚é–“å¸¯ã®ç¨¼åƒç‡æ”¹å–„ã«ç¹‹ãŒã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
            """
        )

    # â‘¤ ãƒãƒ©ãƒ³ã‚¹è‰¯å¥½ â†’ ç¾çŠ¶ç¶­æŒï¼‹å¾®æ”¹å–„
    else:
        st.success(
            f"""
            ç¾åœ¨ã®æ§‹æˆï¼ˆP={adjusted_P}, S={adjusted_S}ï¼‰ã¯åœ°åŸŸã¨æ¯”è¼ƒã—ã¦ãƒãƒ©ãƒ³ã‚¹è‰¯å¥½ã§ã™ã€‚

            **ææ¡ˆ**ï¼šã“ã®çŠ¶æ…‹ã‚’ç¶­æŒã—ã¤ã¤ã€æ—¥æ›¿ã‚ã‚Šã‚¤ãƒ™ãƒ³ãƒˆã‚„SNSæ–½ç­–ã«ã‚ˆã‚‹å¾®æ”¹å–„ã‚’ç‹™ã„ã¾ã—ã‚‡ã†ã€‚
            """
        )

# ãƒšãƒ¼ã‚¸6ï¼šæœˆåˆ¥å£²ä¸Šç›®æ¨™ã¨äºˆæ¸¬
elif st.session_state.selected_page == "æœˆåˆ¥å£²ä¸Šç›®æ¨™ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰":
    #store_name = st.session_state.get("store_name", "åº—èˆ—åæœªè¨­å®š")
    st.markdown(f"### ğŸ¢ ç¾åœ¨ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã®åº—èˆ—ï¼š**{store_name}**")

    st.title("ğŸ“† æœˆåˆ¥å£²ä¸Šç›®æ¨™ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

    import pandas as pd
    import numpy as np
    import joblib
    from datetime import datetime, timedelta

    # ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    model = load_pkl(model_paths["weather"])
    df = pd.read_csv("merged_sales_weather.csv", parse_dates=["æ—¥ä»˜"])
    df["æ—¥ä»˜"] = df["æ—¥ä»˜"].dt.date

    # ä»Šæœˆã®1æ—¥ã€œæœ«æ—¥ã¾ã§ã®æ—¥ä»˜ã‚’ç”Ÿæˆ
    today = datetime.today()
    first_day_this_month = today.replace(day=1)
    last_day_this_month = (first_day_this_month + pd.DateOffset(months=1)) - timedelta(days=1)
    forecast_dates = pd.date_range(start=first_day_this_month, end=last_day_this_month).date
    df_forecast = pd.DataFrame({"æ—¥ä»˜": forecast_dates})

    # ç‰¹å¾´é‡ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆï¼ˆå¹³å‡å€¤ãƒ™ãƒ¼ã‚¹ï¼‰
    feature_cols = [col for col in df.columns if col not in ["æ—¥ä»˜", "å£²ä¸Š", "å°å£²ä¸Šåˆè¨ˆ"]]
    numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()
    feature_template = df[numeric_cols].mean()
    X = pd.DataFrame([feature_template.copy() for _ in range(len(df_forecast))])
    X.reset_index(drop=True, inplace=True)

    # ç‰¹å¾´é‡æ•´å½¢ï¼šä¸è¶³åˆ†ã¯0è£œå®Œã€é †åºã¯ãƒ¢ãƒ‡ãƒ«ã«åˆã‚ã›ã‚‹
    model_features = model.feature_names_in_ if hasattr(model, "feature_names_in_") else X.columns
    for col in model_features:
        if col not in X.columns:
            X[col] = 0
    X = X[model_features]

    # å£²ä¸Šäºˆæ¸¬å®Ÿè¡Œ
    df_forecast["äºˆæ¸¬å£²ä¸Š"] = model.predict(X).astype(int)
    df_forecast["å¹´æœˆ"] = pd.to_datetime(df_forecast["æ—¥ä»˜"]).dt.strftime("%Y-%m")

    # æœˆåˆ¥é›†è¨ˆ
    monthly_result = df_forecast.groupby("å¹´æœˆ")["äºˆæ¸¬å£²ä¸Š"].sum().reset_index()

    # çµæœè¡¨ç¤º
    st.markdown("### ğŸ”® æœˆåˆ¥å£²ä¸Šäºˆæ¸¬")
    st.dataframe(monthly_result)

    st.markdown("### ğŸ¯ ç›®æ¨™å£²ä¸Šã®è¨­å®šã¨æ¯”è¼ƒ")
    for _, row in monthly_result.iterrows():
        month_str = row["å¹´æœˆ"]
        forecast = row["äºˆæ¸¬å£²ä¸Š"]

        target = st.number_input(
            f"{month_str} ã®ç›®æ¨™å£²ä¸Šï¼ˆå††ï¼‰",
            min_value=0,
            key=f"target_{month_str}"
        )

        achieved = forecast >= target

        # é”æˆç‡ï¼ˆé”æˆç‡ = äºˆæ¸¬ / ç›®æ¨™ï¼‰
        #ratio = forecast / target * 100 if target > 0 else 0

        # å·®é¡ã®ä¸­èº«ã¨ãƒ©ãƒ™ãƒ«ã‚’åˆ†å²
        if achieved:
            label = "ä»Šæœˆç›®æ¨™ã¾ã§æ®‹ã‚Š"
            gap = abs (target - forecast)  # é¡§å®¢ã«ã¨ã£ã¦ä½™ã£ã¦ã„ã‚‹é‡‘é¡
        else:
            label = "ä»Šæœˆã®ç›®æ¨™ä½™å‰°é‡‘é¡"
            gap = abs (forecast - target)  # æœªé”æˆé¡ï¼ˆãƒã‚¤ãƒŠã‚¹ã«ãªã‚‹ï¼‰

        # è¡¨ç¤º
        col1, col2 = st.columns(2)
        col1.metric("äºˆæ¸¬å£²ä¸Š", f"{forecast:,} å††")
        col2.metric(
            label,
            f"{gap:+,} å††",
            #delta=f"{ratio:.1f}%",
            delta_color="normal" if achieved else "inverse"
        )

        # ä¸­å¤®ã«é”æˆåˆ¤å®š
        st.markdown(" ")
        col_center = st.columns(3)[1]
        with col_center:
            if achieved:
                st.error("âš ï¸ æœªé”")
            else:
                st.success("âœ… é”æˆ")






# ãƒšãƒ¼ã‚¸6ï¼šæœˆåˆ¥å£²ä¸Šç›®æ¨™ã¨äºˆæ¸¬
elif st.session_state.selected_page == "æœˆåˆ¥å£²ä¸Šç›®æ¨™ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰":
    #store_name = st.session_state.get("store_name", "åº—èˆ—åæœªè¨­å®š")
    st.markdown(f"### ğŸ¢ ç¾åœ¨ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã®åº—èˆ—ï¼š**{store_name}**")

    st.title("ğŸ“† æœˆåˆ¥å£²ä¸Šç›®æ¨™ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

    import pandas as pd
    import numpy as np
    import joblib
    from datetime import datetime, timedelta

    # ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    model = load_pkl(model_paths["weather"])
    df = pd.read_csv("merged_sales_weather.csv", parse_dates=["æ—¥ä»˜"])
    df["æ—¥ä»˜"] = df["æ—¥ä»˜"].dt.date

    # ä»Šæœˆã®1æ—¥ã€œæœ«æ—¥ã¾ã§ã®æ—¥ä»˜ã‚’ç”Ÿæˆ
    today = datetime.today()
    first_day_this_month = today.replace(day=1)
    last_day_this_month = (first_day_this_month + pd.DateOffset(months=1)) - timedelta(days=1)
    forecast_dates = pd.date_range(start=first_day_this_month, end=last_day_this_month).date
    df_forecast = pd.DataFrame({"æ—¥ä»˜": forecast_dates})

    # ç‰¹å¾´é‡ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆï¼ˆå¹³å‡å€¤ãƒ™ãƒ¼ã‚¹ï¼‰
    feature_cols = [col for col in df.columns if col not in ["æ—¥ä»˜", "å£²ä¸Š", "å°å£²ä¸Šåˆè¨ˆ"]]
    numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()
    feature_template = df[numeric_cols].mean()
    X = pd.DataFrame([feature_template.copy() for _ in range(len(df_forecast))])
    X.reset_index(drop=True, inplace=True)

    # ç‰¹å¾´é‡æ•´å½¢ï¼šä¸è¶³åˆ†ã¯0è£œå®Œã€é †åºã¯ãƒ¢ãƒ‡ãƒ«ã«åˆã‚ã›ã‚‹
    model_features = model.feature_names_in_ if hasattr(model, "feature_names_in_") else X.columns
    for col in model_features:
        if col not in X.columns:
            X[col] = 0
    X = X[model_features]

    # å£²ä¸Šäºˆæ¸¬å®Ÿè¡Œ
    df_forecast["äºˆæ¸¬å£²ä¸Š"] = model.predict(X).astype(int)
    df_forecast["å¹´æœˆ"] = pd.to_datetime(df_forecast["æ—¥ä»˜"]).dt.strftime("%Y-%m")

    # æœˆåˆ¥é›†è¨ˆ
    monthly_result = df_forecast.groupby("å¹´æœˆ")["äºˆæ¸¬å£²ä¸Š"].sum().reset_index()

    # çµæœè¡¨ç¤º
    st.markdown("### ğŸ”® æœˆåˆ¥å£²ä¸Šäºˆæ¸¬")
    st.dataframe(monthly_result)

    st.markdown("### ğŸ¯ ç›®æ¨™å£²ä¸Šã®è¨­å®šã¨æ¯”è¼ƒ")
    for _, row in monthly_result.iterrows():
        month_str = row["å¹´æœˆ"]
        forecast = row["äºˆæ¸¬å£²ä¸Š"]

        target = st.number_input(
            f"{month_str} ã®ç›®æ¨™å£²ä¸Šï¼ˆå††ï¼‰",
            min_value=0,
            key=f"target_{month_str}"
        )

        achieved = forecast >= target

        # é”æˆç‡ï¼ˆé”æˆç‡ = äºˆæ¸¬ / ç›®æ¨™ï¼‰
        #ratio = forecast / target * 100 if target > 0 else 0

        # å·®é¡ã®ä¸­èº«ã¨ãƒ©ãƒ™ãƒ«ã‚’åˆ†å²
        if achieved:
            label = "ä»Šæœˆç›®æ¨™ã¾ã§æ®‹ã‚Š"
            gap = abs (target - forecast)  # é¡§å®¢ã«ã¨ã£ã¦ä½™ã£ã¦ã„ã‚‹é‡‘é¡
        else:
            label = "ä»Šæœˆã®ç›®æ¨™ä½™å‰°é‡‘é¡"
            gap = abs (forecast - target)  # æœªé”æˆé¡ï¼ˆãƒã‚¤ãƒŠã‚¹ã«ãªã‚‹ï¼‰

        # è¡¨ç¤º
        col1, col2 = st.columns(2)
        col1.metric("äºˆæ¸¬å£²ä¸Š", f"{forecast:,} å††")
        col2.metric(
            label,
            f"{gap:+,} å††",
            #delta=f"{ratio:.1f}%",
            delta_color="normal" if achieved else "inverse"
        )

        # ä¸­å¤®ã«é”æˆåˆ¤å®š
        st.markdown(" ")
        col_center = st.columns(3)[1]
        with col_center:
            if achieved:
                st.error("âš ï¸ æœªé”")
            else:
                st.success("âœ… é”æˆ")










# ãƒšãƒ¼ã‚¸2ï¼šå£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼
elif st.session_state.selected_page == "å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ä»®":
    #store_name = st.session_state.get("store_name", "åº—èˆ—åæœªè¨­å®š")
    st.markdown(f"### ğŸ¢ ç¾åœ¨ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã®åº—èˆ—ï¼š**{store_name}**")

    st.title("ğŸ“ˆ å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ä»®")
    st.write("ã“ã“ã«äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®å†…å®¹ã‚’ä»®å®Ÿè£…")




    dates = pd.date_range(date.today(), periods=3)
    sales_df = pd.DataFrame({"æ—¥ä»˜": dates, "å£²ä¸Šäºˆæ¸¬(ä¸‡å††)": [230, 260, 240]})
    st.altair_chart(alt.Chart(sales_df).mark_line(point=True).encode(x="æ—¥ä»˜:T", y="å£²ä¸Šäºˆæ¸¬(ä¸‡å††):Q").properties(height=300), use_container_width=True)
    factors_df = pd.DataFrame({"è¦å› ": ["å¤©å€™", "æ›œæ—¥", "ç«¶åˆæ–½ç­–"], "å½±éŸ¿åº¦": [0.12, -0.08, -0.05]})
    factor_chart = alt.Chart(factors_df).mark_bar(size=20).encode(x=alt.X("å½±éŸ¿åº¦:Q", scale=alt.Scale(domain=[-1, 1])), y=alt.Y("è¦å› :N", sort="-x"), color=alt.Color("è¦å› :N")).properties(height=250)
    st.altair_chart(factor_chart, use_container_width=True)


    st.altair_chart(
        alt.Chart(sales_df).mark_line(point=True).encode(
            x="æ—¥ä»˜:T",
            y="å£²ä¸Šäºˆæ¸¬(ä¸‡å††):Q"
        ).properties(height=300),
        use_container_width=True
    )


    st.write("\n**è¦å› åˆ¥åˆ†æï¼ˆä»®ãƒ‡ãƒ¼ã‚¿ï¼‰**")
    factors_df = pd.DataFrame({
        "è¦å› ": ["å¤©å€™", "æ›œæ—¥", "ç«¶åˆæ–½ç­–"],
        "å½±éŸ¿åº¦": [0.12, -0.08, -0.05]
    })
    factor_chart = alt.Chart(factors_df).mark_bar(size=20).encode(
        x=alt.X("å½±éŸ¿åº¦:Q", scale=alt.Scale(domain=[-1, 1])),
        y=alt.Y("è¦å› :N", sort="-x"),
        color=alt.Color("è¦å› :N")
    ).properties(height=250)
    st.altair_chart(factor_chart, use_container_width=True)


# ãƒšãƒ¼ã‚¸2ï¼šåœ°ç†ãƒãƒƒãƒ—åˆ†æ
elif st.session_state.selected_page == "åœ°ç†ãƒãƒƒãƒ—åˆ†æ":
    st.title("ğŸ—º åœ°ç†ãƒãƒƒãƒ—åˆ†æ")
    st.write("ã“ã“ã«Foliumãªã©ã§åœ°å›³ã‚’è¡¨ç¤º")

    tab1, tab2 = st.tabs(["ã‚·ãƒ³ãƒ—ãƒ«åœ°å›³", "Huffã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"])

    df_town = pd.read_csv("./data/miyazaki_city_with_latlon.csv", encoding="utf-8")
    df_raw = pd.read_csv("./data/miyazaki_5pachi_geocode.csv", encoding="shift_jis")
    df_store = pd.DataFrame({
        'name': df_raw['ãƒ›ãƒ¼ãƒ«å'],
        'size': df_raw['På°æ•°'] + df_raw['Så°æ•°'],
        'lat': df_raw['ç·¯åº¦'],
        'lon': df_raw['çµŒåº¦']
    })


    with tab1:
        st.map(df_store.rename(columns={'lat': 'latitude', 'lon': 'longitude'}))
        st.dataframe(df_store)


    with tab2:
        st.markdown("### Huffãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸã‚·ã‚§ã‚¢ãƒ»æ¥åº—äºˆæ¸¬")
        alpha = st.slider("è·é›¢æ¸›è¡°ä¿‚æ•° Î±", 1.0, 3.0, 1.5, step=0.1)
        hour = st.selectbox("æ™‚é–“å¸¯", [8, 12, 18], index=1)
        weather_factor = st.slider("å¤©å€™ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼", 0.4, 1.0, 0.8, step=0.1)


        time_factors = {8: 0.7, 12: 0.93, 18: 0.8}
        pop_factor = time_factors.get(hour, 1.0) * weather_factor
        pop_dyn = df_town['population'] * pop_factor
        pop_sum = pop_dyn.sum()


        def haversine(lat1, lon1, lat2, lon2):
            R = 6371
            phi1, phi2 = map(math.radians, (lat1, lat2))
            dphi = math.radians(lat2 - lat1)
            dlmb = math.radians(lon2 - lon1)
            a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlmb/2)**2
            return 2 * R * math.atan2(math.sqrt(a), math.sqrt(1 - a))


        shares = []
        for store in df_store.itertuples():
            dists = df_town.apply(lambda t: haversine(t['latitude'], t['longitude'], store.lat, store.lon) + 1e-6, axis=1)
            weights = store.size / (dists ** alpha)
            pij = weights / weights.sum()
            share = (pop_dyn * pij).sum() / pop_sum
            shares.append(share)


        df_store['share'] = shares
        max_share = max(shares)


        st.subheader(" åº—èˆ—ã‚·ã‚§ã‚¢ä¸€è¦§")
        st.dataframe(df_store[['name', 'share']].sort_values('share', ascending=False))


        st.subheader(" ã‚·ã‚§ã‚¢æ£’ã‚°ãƒ©ãƒ•")
        share_chart = alt.Chart(df_store).mark_bar(size=10).encode(
            x=alt.X("share:Q", scale=alt.Scale(domain=[0, max_share])),
            y=alt.Y("name:N", sort="-x"),
            color=alt.Color("name:N")
        ).properties(height=600)
        st.altair_chart(share_chart, use_container_width=True)


        st.subheader(" ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆæ¥åº—äºˆæ¸¬ï¼‰")
        visits_pred = []
        for _, town in df_town.iterrows():
            dists = df_store.apply(lambda s: haversine(town['latitude'], town['longitude'], s.lat, s.lon) + 1e-6, axis=1)
            weights = df_store['size'] / (dists ** alpha)
            pij = weights / weights.sum()
            visits_pred.append((pop_dyn * pij).sum())
        df_town['visits_pred'] = visits_pred


        heat_df = df_town[['latitude', 'longitude', 'visits_pred']].dropna()
        m1 = folium.Map(location=[df_town['latitude'].mean(), df_town['longitude'].mean()], zoom_start=12)
        HeatMap(heat_df.values.tolist(), radius=20).add_to(m1)
        folium_static(m1, width=800, height=450)


        st.subheader(" ãƒãƒ–ãƒ«ãƒãƒƒãƒ—ï¼ˆåº—èˆ—ã‚·ã‚§ã‚¢ï¼‰")
        m2 = folium.Map(location=[df_town['latitude'].mean(), df_town['longitude'].mean()], zoom_start=12)
        for store in df_store.itertuples():
            r = (store.share / max_share) * 300
            folium.Circle(location=[store.lat, store.lon], radius=r, fill=True, fill_opacity=0.6).add_to(m2)
        folium_static(m2, width=800, height=450)


# ãƒšãƒ¼ã‚¸3ï¼šãƒ›ãƒ¼ãƒ«å†…ãƒ©ãƒ³ã‚­ãƒ³ã‚°

elif st.session_state.selected_page == "ãƒ›ãƒ¼ãƒ«å†…ãƒ©ãƒ³ã‚­ãƒ³ã‚°":
    #store_name = st.session_state.get("store_name", "åº—èˆ—åæœªè¨­å®š")
    st.markdown(f"### ğŸ¢ ç¾åœ¨ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã®åº—èˆ—ï¼š**{store_name}**")

    st.title("ãƒ›ãƒ¼ãƒ«å†…ãƒ©ãƒ³ã‚­ãƒ³ã‚°(å…¨åº—èˆ—å¥‘ç´„ç‰¹å…¸)")
    st.write("ãƒ›ãƒ¼ãƒ«å†…ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°æƒ…å ±ã‚’è¡¨ç¤º")

    stores_df = pd.DataFrame({
        "æ‹ ç‚¹": ["Aåº—", "Båº—", "Cåº—"],
        "å£²ä¸Šäºˆæ¸¬(ä¸‡å††)": [250, 195, 180],
        "å·®åˆ†": ["+4%", "-8%", "+6%"],
        "ä¸»ãªè¦å› ": ["æ›œæ—¥", "é›¨Ã—ç«¶åˆ", "å¤©å€™"]
    })
    st.dataframe(stores_df)


# ãƒšãƒ¼ã‚¸4ï¼šæ™‚ç³»åˆ—ã‚·ãƒŠãƒªã‚ªåˆ†æ
# elif menu == "æ™‚ç³»åˆ—ã‚·ãƒŠãƒªã‚ªåˆ†æ":
#     st.subheader("å£²ä¸Šã®æ™‚ç³»åˆ—ã‚·ãƒŠãƒªã‚ªåˆ†æ")


#     timeline = pd.date_range(start="2024-01-01", periods=12, freq="M")
#     sales_series = pd.DataFrame({"æœˆ": timeline, "å£²ä¸Š(ä¸‡å††)": [220, 210, 230, 250, 270, 260, 255, 245, 240, 250, 265, 275]})


#     st.line_chart(sales_series.rename(columns={"æœˆ": "index"}).set_index("index"))


# ãƒšãƒ¼ã‚¸5ï¼šå£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼
# # ãƒšãƒ¼ã‚¸5ï¼šå£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼
# elif st.session_state.selected_page == "å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼":
#     st.title("å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼")
#     st.write("XGBoostãƒ¢ãƒ‡ãƒ«")

#     import joblib
#     import shap
#     import matplotlib.pyplot as plt
#     import pandas as pd
#     import numpy as np
#     from datetime import timedelta
#     model_weather = load_pkl(model_paths["weather"])
#     explainer = shap.Explainer(model_weather)
#     model_hit = load_pkl(model_paths["hit"])
#     model_profit = load_pkl(model_paths["profit"])
#     model_sales = load_pkl(model_paths["sales"])
#     model_base = load_pkl(model_paths["base"])


#     df = pd.read_csv("merged_sales_weather.csv", parse_dates=["æ—¥ä»˜"])
#     df["æ—¥ä»˜"] = pd.to_datetime(df["æ—¥ä»˜"]).dt.date

#     start_date = st.date_input("äºˆæ¸¬é–‹å§‹æ—¥")
#     forecast_days = st.slider("äºˆæ¸¬æ—¥æ•°ï¼ˆæœ€å¤§30æ—¥ï¼‰", 1, 30, 7)

#     forecast_dates = pd.date_range(start=start_date, periods=forecast_days).date
#     df_forecast = pd.DataFrame({"æ—¥ä»˜": forecast_dates})

#     if df_forecast.empty:
#         st.warning("æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜ç¯„å›²ã«è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
#     else:
#         feature_cols = [col for col in df.columns if col not in ["æ—¥ä»˜", "å£²ä¸Š"]]

#         # æ•°å€¤åˆ—ã®ã¿å¹³å‡ã§ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ
#         numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()
#         feature_template = df[numeric_cols].mean()

#         X = pd.DataFrame([feature_template.copy() for _ in range(len(df_forecast))])
#         X.reset_index(drop=True, inplace=True)

#         # æ‰“è¾¼ãƒ»å°ç²—åˆ©ãƒ»å°å£²ä¸Šã‚’å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã—ã¦è£œå®Œ
#         hit_X = df[model_hit.feature_names_in_].iloc[0:len(df_forecast)].copy()
#         profit_X = df[model_profit.feature_names_in_].iloc[0:len(df_forecast)].copy()
#         sales_X = df[model_sales.feature_names_in_].iloc[0:len(df_forecast)].copy()

#         for mX in [hit_X, profit_X, sales_X]:
#             for col in mX.select_dtypes(include='object').columns:
#                 mX[col] = pd.factorize(mX[col])[0]

#         X["æ‰“è¾¼"] = model_hit.predict(hit_X)
#         X["å°ç²—åˆ©"] = model_profit.predict(profit_X)
#         X["å°å£²ä¸Š"] = model_sales.predict(sales_X)

#         # ç‰¹å¾´é‡æ•´å½¢
#         model_features = model.feature_names_in_ if hasattr(model, "feature_names_in_") else X.columns
#         missing_cols = [col for col in model_features if col not in X.columns]
#         for col in missing_cols:
#             X[col] = 0
#         X = X[model_features]

#         y_pred = model.predict(X)
#         df_result = df_forecast[["æ—¥ä»˜"]].copy()
#         df_result["äºˆæ¸¬å£²ä¸Š"] = y_pred.astype(int)

#         st.markdown("#### äºˆæ¸¬å£²ä¸Šä¸€è¦§")
#         st.dataframe(df_result)
#         st.line_chart(df_result.set_index("æ—¥ä»˜"))

#         st.markdown("#### ç‰¹å¾´é‡ã®å¹³å‡SHAPé‡è¦åº¦")
#         shap_values_all = explainer(X)
#         mean_shap = abs(shap_values_all.values).mean(axis=0)
#         shap_df = pd.DataFrame({"ç‰¹å¾´é‡": X.columns, "å¹³å‡é‡è¦åº¦": mean_shap})
#         st.bar_chart(shap_df.set_index("ç‰¹å¾´é‡"))

#         st.markdown("#### å£²ä¸Šä¸Šä½3æ—¥ã®è¦å› åˆ†æ (SHAP)")
#         top3 = df_result.sort_values("äºˆæ¸¬å£²ä¸Š", ascending=False).head(3)
#         for row in top3.itertuples():
#             idx = df_forecast[df_forecast["æ—¥ä»˜"] == row.æ—¥ä»˜].index[0]
#             shap_values = explainer(X.iloc[[idx]])
#             st.markdown(f"**{row.æ—¥ä»˜.strftime('%Y-%m-%d')} ã®SHAPè¦å› **")
#             fig = plt.figure()
#             shap.plots.waterfall(shap_values[0], show=False)
#             st.pyplot(fig)
#             plt.clf()






# #ä»®ãƒšãƒ¼ã‚¸
# elif st.session_state.selected_page == "å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼ˆæœ€é©åŒ–ï¼‰":
#     store_name = st.session_state.get("store_name", "åº—èˆ—åæœªè¨­å®š")
#     st.markdown(f"### ğŸ¢ ç¾åœ¨ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã®åº—èˆ—ï¼š**{store_name}**")

#     st.title("ğŸ¯ å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼ˆæœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«ï¼‰")

#     import joblib
#     import pandas as pd
#     from datetime import date

#     try:
#         model = load_pkl(model_paths["weather"])

#     except Exception as e:
#         st.error("âŒ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
#         st.exception(e)
#         st.stop()

#     # å…¥åŠ›æ¬„
#     target_date = st.date_input("äºˆæ¸¬æ—¥", value=date.today())
#     weekday = target_date.weekday()
#     hour = st.selectbox("æ™‚é–“å¸¯", [8, 12, 18], index=1)

#     store = st.selectbox("åº—èˆ—", ["Aåº—", "Båº—", "Cåº—"])
#     p_table = {"Aåº—": 400, "Båº—": 300, "Cåº—": 350}
#     s_table = {"Aåº—": 200, "Båº—": 150, "Cåº—": 180}
#     P = p_table[store]
#     S = s_table[store]

#     if st.button("å£²ä¸Šã‚’äºˆæ¸¬ã™ã‚‹"):
#         try:
#             X_input = pd.DataFrame([[weekday, hour, P, S]],
#                 columns=["æ›œæ—¥_x", "æ™‚é–“å¸¯", "På°æ•°", "Så°æ•°"])  # ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡ã«åˆã‚ã›ã¦å¤‰æ›´
#             y_pred = model.predict(X_input)[0]
#             st.success(f"ğŸ“… {target_date} ã®äºˆæ¸¬å£²ä¸Šï¼šÂ¥{int(y_pred):,} å††")
#         except Exception as e:
#             st.error("âŒ äºˆæ¸¬å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
#             st.exception(e)







# ãƒšãƒ¼ã‚¸6ï¼šå£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼ˆWhat-ifåˆ†æ)
# --- ã‚¿ã‚¤ãƒˆãƒ«ãƒ»åˆæœŸæƒ…å ± ---
elif st.session_state.selected_page == "What-ifã‚·ãƒŠãƒªã‚ªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼":
    store_name = st.session_state.get("store_name", "åº—èˆ—åæœªè¨­å®š")
    st.markdown(f"### \U0001f3e2 ç¾åœ¨ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã®åº—èˆ—ï¼š**{store_name}**")

    st.title("What-ifåˆ†æ")
    st.write("å°æ•°å¤‰æ›´ã‚„æ–½ç­–ã‚’å¤‰ãˆãŸå ´åˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")

    # --- åº—èˆ—ã”ã¨ã®ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ ---
    store_folder_map = {
        "ã‚ªãƒ¼ãƒ‘ã‚¹å®®å´æœ¬åº—": "miyazaki",
        "ã‚ªãƒ¼ãƒ‘ã‚¹å°æ¾": "komatsudai",
        "ã‚ªãƒ¼ãƒ‘ã‚¹éƒ½åŸåº—": "miyakonojo"
    }
    store_folder = store_folder_map.get(store_name, "miyazaki")
    model_path = f"store_data/{store_folder}/model_weather.pkl"

    try:
        model = joblib.load(model_path)
        explainer = shap.Explainer(model)
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        st.stop()

    # --- å…¥åŠ›UI ---
    date_selected = st.date_input("åˆ†ææ—¥")
    #hour = st.selectbox("æ™‚é–“å¸¯", [8, 12, 18], index=1)
    weekday = date_selected.weekday()

    st.markdown("å¤–éƒ¨ç’°å¢ƒé …ç›®ï¼ˆå¤©å€™ãƒ»é¡§å®¢ç‰¹æ€§ãªã©ï¼‰")
    å‡ºç‰ç‡ = st.slider("å‡ºç‰ç‡ï¼ˆ%ï¼‰", 85.0, 105.0, 94.0, step=0.1)
    å®¢æ»ç‡ = st.slider("å®¢æ»ç‡ï¼ˆ%ï¼‰", 130.0, 200.0, 165.0, step=0.1)
    å¹³å‡æ°—æ¸© = st.slider("å¹³å‡æ°—æ¸© (â„ƒ)", -5.0, 40.0, 18.0, step=0.5)
    æœ€é«˜æ°—æ¸© = st.slider("æœ€é«˜æ°—æ¸© (â„ƒ)", -5.0, 45.0, 25.0, step=0.5)
    æœ€ä½æ°—æ¸© = st.slider("æœ€ä½æ°—æ¸© (â„ƒ)", -10.0, 30.0, 12.0, step=0.5)
    æ—¥ç…§æ™‚é–“ = st.slider("æ—¥ç…§æ™‚é–“ (h)", 0.0, 15.0, 8.0, step=0.5)
    å¹³å‡æ°—åœ§ = st.slider("å¹³å‡æ°—åœ§ (hPa)", 990.0, 1040.0, 1010.0, step=0.5)
    æœ€å¤§é¢¨é€Ÿ = st.slider("æœ€å¤§é¢¨é€Ÿ (m/s)", 0.0, 40.0, 10.0, step=0.5)
    æœ€å¤§ç¬é–“é¢¨é€Ÿ = st.slider("æœ€å¤§ç¬é–“é¢¨é€Ÿ (m/s)", 0.0, 50.0, 15.0, step=0.5)
    å¹³å‡é¢¨é€Ÿ = st.slider("å¹³å‡é¢¨é€Ÿ (m/s)", 0.0, 20.0, 5.0, step=0.5)
    é™æ°´é‡ = st.slider("é™æ°´é‡ (mm)", 0.0, 200.0, 0.0, step=1.0)
    æ‰“è¾¼ = st.slider("æ‰“è¾¼ (ç·æŠ•å…¥æ•°)", 0.0, 20000.0, 8000.0, step=100.0)

    st.markdown("æ¡ä»¶æ¯”è¼ƒã‚·ãƒŠãƒªã‚ª(éå»ï¼’å¹´å†…ã«åŒåº—èˆ—å†…ã§å°æ•°ã®ä¸Šä¸‹ãŒãªã„å ´åˆã¯æ©Ÿèƒ½ã—ã¾ã›ã‚“)")
    base_P = st.slider("ãƒ™ãƒ¼ã‚¹På°æ•°", 100, 600, 400, step=10)
    base_S = st.slider("ãƒ™ãƒ¼ã‚¹Så°æ•°", 50, 300, 200, step=10)
    delta_P = st.slider("På°æ•°ã®å¢—æ¸›ã‚·ãƒŠãƒªã‚ª", -100, 100, 0, step=10)
    delta_S = st.slider("Så°æ•°ã®å¢—æ¸›ã‚·ãƒŠãƒªã‚ª", -100, 100, 0, step=10)
    P1, S1 = base_P, base_S
    P2, S2 = base_P + delta_P, base_S + delta_S

    def make_input(P, S):
        return pd.DataFrame([{
            "æ›œæ—¥_x": weekday,
            "æ‰“è¾¼": æ‰“è¾¼,
            "å‡ºç‰ç‡": å‡ºç‰ç‡,
            "å®¢æ»ç‡": å®¢æ»ç‡,
            "å°æ•°": P + S,
            "å¹³å‡æ°—æ¸©": å¹³å‡æ°—æ¸©,
            "æœ€é«˜æ°—æ¸©": æœ€é«˜æ°—æ¸©,
            "æœ€ä½æ°—æ¸©": æœ€ä½æ°—æ¸©,
            "æ—¥ç…§æ™‚é–“": æ—¥ç…§æ™‚é–“,
            "å¹³å‡æ°—åœ§": å¹³å‡æ°—åœ§,
            "æœ€å¤§é¢¨é€Ÿ": æœ€å¤§é¢¨é€Ÿ,
            "æœ€å¤§ç¬é–“é¢¨é€Ÿ": æœ€å¤§ç¬é–“é¢¨é€Ÿ,
            "å¹³å‡é¢¨é€Ÿ": å¹³å‡é¢¨é€Ÿ,
            "é™æ°´é‡": é™æ°´é‡
        }])

    def prepare_input(df):
        for col in model.feature_names_:
            if col not in df.columns:
                df[col] = 0
        df = df[model.feature_names_]
        for col in df.select_dtypes(include=["object"]):
            df[col] = pd.factorize(df[col])[0]
        return df

    # --- ãƒ™ãƒ¼ã‚¹å€¤ä¿å­˜æ©Ÿæ§‹ ---
    if "X_base_saved" not in st.session_state:
        st.session_state.X_base_saved = None

    if st.button("ã“ã®è¨­å®šã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä¿å­˜"):
        st.session_state.X_base_saved = make_input(P1, S1)
        st.success("ãƒ™ãƒ¼ã‚¹å…¥åŠ›ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

    if st.session_state.X_base_saved is not None:
        X_base = prepare_input(st.session_state.X_base_saved)
        pred_base = model.predict(X_base)[0]
    else:
        st.warning("ãƒ™ãƒ¼ã‚¹è¨­å®šã‚’ä¿å­˜ã—ã¦ãã ã•ã„ï¼ˆä¸Šã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ï¼‰")
        pred_base = None

    X_scenario = prepare_input(make_input(P2, S2))
    pred_scenario = model.predict(X_scenario)[0]

    if pred_base is not None:
        st.success(f"ãƒ™ãƒ¼ã‚¹äºˆæ¸¬ï¼šÂ¥{int(pred_base):,} â†’ ã‚·ãƒŠãƒªã‚ªäºˆæ¸¬ï¼šÂ¥{int(pred_scenario):,} å††")

    st.markdown("#### SHAPè¦å› æ¯”è¼ƒ (ã‚·ãƒŠãƒªã‚ªå´)")
    shap_values = explainer(X_scenario)
    fig = plt.figure()
    shap.plots.waterfall(shap_values[0], show=False)
    st.pyplot(fig)
    plt.clf()



# #7ãƒšãƒ¼ã‚¸ç›®
# elif menu == "å°æ•°å¤‰åŒ– vs å£²ä¸Šã‚°ãƒ©ãƒ•":
#     st.subheader("æ„Ÿå¿œåº¦åˆ†æï¼šPÃ—S å°æ•°ã®å¤‰åŒ–ã«ã‚ˆã‚‹å£²ä¸Šå½±éŸ¿ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰")

#     import joblib
#     import pandas as pd
#     import plotly.graph_objs as go
#     import shap
#     import matplotlib.pyplot as plt
#     from fpdf import FPDF
#     import tempfile

#     model_sales = joblib.load("model_sales.pkl")
#     model_profit = joblib.load("model_profit.pkl")
#     explainer = shap.Explainer(model_sales)

#     # ç‰¹å®šæ—¥å›ºå®š
#     date_selected = st.date_input("åˆ†ææ—¥")
#     weekday = date_selected.weekday()
#     hour = st.selectbox("æ™‚é–“å¸¯", [8, 12, 18], index=1)

#     # å›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå¤–éƒ¨ç’°å¢ƒï¼‰
#     å‡ºç‰ç‡ = 94.0
#     å®¢æ»ç‡ = 165.0
#     å¹³å‡æ°—æ¸© = 18.0
#     æœ€é«˜æ°—æ¸© = 25.0
#     æœ€ä½æ°—æ¸© = 12.0
#     æ—¥ç…§æ™‚é–“_æ™‚é–“ = 8.0
#     å¹³å‡ç¾åœ°æ°—åœ§_hPa = 1010.0
#     æœ€å¤§é¢¨é€Ÿ_m_s = 10.0
#     æœ€å¤§é¢¨é€Ÿ_m_s_2 = 10.0
#     å¹³å‡é¢¨é€Ÿ_m_s = 5.0
#     é™æ°´é‡ = 0.0
#     å°å£²ä¸Šåˆè¨ˆ = 0.0
#     å°ç²—åˆ©åˆè¨ˆ = 0.0
#     ç·æ‰“è¾¼ = 8000.0
#     åˆ©ç›Šç‡ = 0.0
#     æœ‰åŠ¹S = 0.0
#     å…¥è³S1 = 0.0
#     BA = 0.0
#     MY = 0.0
#     ç‰å˜ä¾¡ = 0.0
#     ç‰åˆ© = 0.0
#     å‰²æ•° = 0.0
#     å‹ç‡ = 0.0
#     æ™¯å“é¡å¹³å‡ = 0.0
#     å…ƒãƒ•ã‚¡ã‚¤ãƒ« = 0  # æ•°å€¤ã«å¤‰æ›´
#     æ›œæ—¥_y = weekday

#     # å°æ•°ã‚’å¤‰åŒ–ã•ã›ã¦å£²ä¸Šäºˆæ¸¬ã¨SHAPåˆè¨ˆï¼ˆ1Dï¼‰
#     model_hit = joblib.load("model_hit.pkl")
#     delta_range = range(-100, 101, 10)
#     sales_predictions = []

#     for delta in delta_range:
#         P = 400 + delta
#         S = 200 + delta
#         # ç’°å¢ƒç‰¹å¾´é‡ã ã‘ã‚’ä½¿ã£ã¦æ‰“è¾¼ã‚’äºˆæ¸¬
#         hit_features = pd.DataFrame([{"æ›œæ—¥_x": weekday, "å‡ºç‰ç‡": å‡ºç‰ç‡, "å®¢æ»ç‡": å®¢æ»ç‡, "å°æ•°": P + S, "å¹³å‡æ°—æ¸©": å¹³å‡æ°—æ¸©, "æœ€é«˜æ°—æ¸©": æœ€é«˜æ°—æ¸©, "æœ€ä½æ°—æ¸©": æœ€ä½æ°—æ¸©, "æ—¥ç…§æ™‚é–“(æ™‚é–“)": æ—¥ç…§æ™‚é–“_æ™‚é–“, "å¹³å‡ç¾åœ°æ°—åœ§(hPa)": å¹³å‡ç¾åœ°æ°—åœ§_hPa, "æœ€å¤§é¢¨é€Ÿ(m/s)": æœ€å¤§é¢¨é€Ÿ_m_s, "æœ€å¤§é¢¨é€Ÿ(m/s).2": æœ€å¤§é¢¨é€Ÿ_m_s_2, "å¹³å‡é¢¨é€Ÿ(m/s)": å¹³å‡é¢¨é€Ÿ_m_s, "é™æ°´é‡": é™æ°´é‡}])
#         ç·æ‰“è¾¼ = model_hit.predict(hit_features)[0]

#         input_data = pd.DataFrame([{
#             "æ›œæ—¥_x": weekday, "å°å£²ä¸Šåˆè¨ˆ": å°å£²ä¸Šåˆè¨ˆ, "å°ç²—åˆ©åˆè¨ˆ": å°ç²—åˆ©åˆè¨ˆ, "ç·æ‰“è¾¼": ç·æ‰“è¾¼, "åˆ©ç›Šç‡": åˆ©ç›Šç‡,
#             "æœ‰åŠ¹S": æœ‰åŠ¹S, "å…¥è³S1": å…¥è³S1, "BA": BA, "MY": MY, "å‡ºç‰ç‡": å‡ºç‰ç‡,
#             "å®¢æ»ç‡": å®¢æ»ç‡, "ç‰å˜ä¾¡": ç‰å˜ä¾¡, "ç‰åˆ©": ç‰åˆ©, "å‰²æ•°": å‰²æ•°, "å‹ç‡": å‹ç‡,
#             "æ™¯å“é¡å¹³å‡": æ™¯å“é¡å¹³å‡, "å°æ•°": P + S, "å…ƒãƒ•ã‚¡ã‚¤ãƒ«": å…ƒãƒ•ã‚¡ã‚¤ãƒ«, "æ›œæ—¥_y": æ›œæ—¥_y,
#             "å¹³å‡æ°—æ¸©": å¹³å‡æ°—æ¸©, "æœ€é«˜æ°—æ¸©": æœ€é«˜æ°—æ¸©, "æœ€ä½æ°—æ¸©": æœ€ä½æ°—æ¸©,
#             "æ—¥ç…§æ™‚é–“(æ™‚é–“)": æ—¥ç…§æ™‚é–“_æ™‚é–“, "å¹³å‡ç¾åœ°æ°—åœ§(hPa)": å¹³å‡ç¾åœ°æ°—åœ§_hPa,
#             "æœ€å¤§é¢¨é€Ÿ(m/s)": æœ€å¤§é¢¨é€Ÿ_m_s, "æœ€å¤§é¢¨é€Ÿ(m/s).2": æœ€å¤§é¢¨é€Ÿ_m_s_2,
#             "å¹³å‡é¢¨é€Ÿ(m/s)": å¹³å‡é¢¨é€Ÿ_m_s, "é™æ°´é‡": é™æ°´é‡
#         }])
#         y_pred = model_sales.predict(input_data)[0]
#         y_profit = model_profit.predict(input_data)[0]
#         shap_values = explainer(input_data)
#         shap_sum = shap_values.values[0].sum()
#         sales_predictions.append({
#             "På°æ•°": P, "Så°æ•°": S,
#             "äºˆæ¸¬å£²ä¸Š": y_pred, "äºˆæ¸¬ç²—åˆ©": y_profit, "SHAPåˆè¨ˆ": shap_sum
#         })

#     df_result = pd.DataFrame(sales_predictions)
#     st.line_chart(df_result.set_index("På°æ•°")[["äºˆæ¸¬å£²ä¸Š", "äºˆæ¸¬ç²—åˆ©"]])
#     st.dataframe(df_result)

#     # PDFå‡ºåŠ›
#     with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
#         pdf = FPDF()
#         pdf.add_page()
#         pdf.add_font("Noto", '', "NotoSansJP-VariableFont_wght.ttf", uni=True)
#         pdf.set_font("Noto", size=12)
#         pdf.cell(200, 10, txt="å°æ•°æ„Ÿå¿œåº¦åˆ†æãƒ¬ãƒãƒ¼ãƒˆ", ln=True)
#         pdf.ln()
#         for row in df_result.itertuples():
#             line = f"P={row.På°æ•°}, S={row.Så°æ•°} â†’ å£²ä¸Š: Â¥{int(row.äºˆæ¸¬å£²ä¸Š):,}, ç²—åˆ©: Â¥{int(row.äºˆæ¸¬ç²—åˆ©):,}"
#             pdf.cell(200, 8, txt=line, ln=True)
#         pdf.output(tmp.name)
#         with open(tmp.name, "rb") as f:
#             st.download_button("ğŸ“„ PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", f, file_name="å°æ•°æ„Ÿå¿œåº¦ãƒ¬ãƒãƒ¼ãƒˆ.pdf")

#     # 3Dæ„Ÿå¿œåº¦åˆ†æ
#     st.subheader("æ„Ÿå¿œåº¦åˆ†æï¼šPÃ—S å°æ•°ã¨å£²ä¸Šã®é–¢ä¿‚ï¼ˆPlotly 3Dï¼‰")
#     delta_range_3d = range(-100, 101, 20)
#     results = []

#     for dP in delta_range_3d:
#         for dS in delta_range_3d:
#             P = 400 + dP
#             S = 200 + dS
#             # ç’°å¢ƒç‰¹å¾´é‡ã§æ‰“è¾¼ã‚’äºˆæ¸¬
#             hit_features = pd.DataFrame([{"æ›œæ—¥_x": weekday, "å‡ºç‰ç‡": å‡ºç‰ç‡, "å®¢æ»ç‡": å®¢æ»ç‡, "å°æ•°": P + S, "å¹³å‡æ°—æ¸©": å¹³å‡æ°—æ¸©, "æœ€é«˜æ°—æ¸©": æœ€é«˜æ°—æ¸©, "æœ€ä½æ°—æ¸©": æœ€ä½æ°—æ¸©, "æ—¥ç…§æ™‚é–“(æ™‚é–“)": æ—¥ç…§æ™‚é–“_æ™‚é–“, "å¹³å‡ç¾åœ°æ°—åœ§(hPa)": å¹³å‡ç¾åœ°æ°—åœ§_hPa, "æœ€å¤§é¢¨é€Ÿ(m/s)": æœ€å¤§é¢¨é€Ÿ_m_s, "æœ€å¤§é¢¨é€Ÿ(m/s).2": æœ€å¤§é¢¨é€Ÿ_m_s_2, "å¹³å‡é¢¨é€Ÿ(m/s)": å¹³å‡é¢¨é€Ÿ_m_s, "é™æ°´é‡": é™æ°´é‡}])
#             ç·æ‰“è¾¼ = model_hit.predict(hit_features)[0]

#             input_data = pd.DataFrame([{
#                 "æ›œæ—¥_x": weekday, "å°å£²ä¸Šåˆè¨ˆ": å°å£²ä¸Šåˆè¨ˆ, "å°ç²—åˆ©åˆè¨ˆ": å°ç²—åˆ©åˆè¨ˆ, "ç·æ‰“è¾¼": ç·æ‰“è¾¼, "åˆ©ç›Šç‡": åˆ©ç›Šç‡,
#                 "æœ‰åŠ¹S": æœ‰åŠ¹S, "å…¥è³S1": å…¥è³S1, "BA": BA, "MY": MY, "å‡ºç‰ç‡": å‡ºç‰ç‡,
#                 "å®¢æ»ç‡": å®¢æ»ç‡, "ç‰å˜ä¾¡": ç‰å˜ä¾¡, "ç‰åˆ©": ç‰åˆ©, "å‰²æ•°": å‰²æ•°, "å‹ç‡": å‹ç‡,
#                 "æ™¯å“é¡å¹³å‡": æ™¯å“é¡å¹³å‡, "å°æ•°": P + S, "å…ƒãƒ•ã‚¡ã‚¤ãƒ«": å…ƒãƒ•ã‚¡ã‚¤ãƒ«, "æ›œæ—¥_y": æ›œæ—¥_y,
#                 "å¹³å‡æ°—æ¸©": å¹³å‡æ°—æ¸©, "æœ€é«˜æ°—æ¸©": æœ€é«˜æ°—æ¸©, "æœ€ä½æ°—æ¸©": æœ€ä½æ°—æ¸©,
#                 "æ—¥ç…§æ™‚é–“(æ™‚é–“)": æ—¥ç…§æ™‚é–“_æ™‚é–“, "å¹³å‡ç¾åœ°æ°—åœ§(hPa)": å¹³å‡ç¾åœ°æ°—åœ§_hPa,
#                 "æœ€å¤§é¢¨é€Ÿ(m/s)": æœ€å¤§é¢¨é€Ÿ_m_s, "æœ€å¤§é¢¨é€Ÿ(m/s).2": æœ€å¤§é¢¨é€Ÿ_m_s_2,
#                 "å¹³å‡é¢¨é€Ÿ(m/s)": å¹³å‡é¢¨é€Ÿ_m_s, "é™æ°´é‡": é™æ°´é‡
#             }])
#             y_pred = model_sales.predict(input_data)[0]
#             results.append({"På°æ•°": P, "Så°æ•°": S, "äºˆæ¸¬å£²ä¸Š": y_pred})

#     df_grid = pd.DataFrame(results)
#     st.dataframe(df_grid)

#     fig = go.Figure(data=[go.Surface(
#         z=df_grid["äºˆæ¸¬å£²ä¸Š"].values.reshape(len(delta_range_3d), len(delta_range_3d)),
#         x=df_grid["På°æ•°"].values.reshape(len(delta_range_3d), len(delta_range_3d)),
#         y=df_grid["Så°æ•°"].values.reshape(len(delta_range_3d), len(delta_range_3d)),
#         colorscale='Viridis'
#     )])
#     fig.update_layout(
#         title="PÃ—Sæ„Ÿå¿œåº¦åˆ†æï¼ˆå£²ä¸Šäºˆæ¸¬ï¼‰",
#         scene=dict(
#             xaxis_title='På°æ•°',
#             yaxis_title='Så°æ•°',
#             zaxis_title='äºˆæ¸¬å£²ä¸Š'
#         ),
#         margin=dict(l=0, r=0, b=0, t=40)
#     )
#     st.plotly_chart(fig, use_container_width=True)




#8ãƒšãƒ¼ã‚¸ç›®
elif st.session_state.selected_page == "ã‚¤ãƒ™ãƒ³ãƒˆå½±éŸ¿åˆ†æ":
    store_name = st.session_state.get("store_name", "åº—èˆ—åæœªè¨­å®š")
    st.markdown(f"### ğŸ¢ ç¾åœ¨ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã®åº—èˆ—ï¼š**{store_name}**")

    st.title("ã‚¤ãƒ™ãƒ³ãƒˆåˆ†æ")
    st.write("ã‚¤ãƒ™ãƒ³ãƒˆã«ã‚ˆã‚‹å£²ä¸Šã¸ã®å½±éŸ¿ã‚’å¯è¦–åŒ–")


    # ä»®ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿
    sales_csv = """date,actual_sales,predicted_sales
    2025-05-01,800000,820000
    2025-05-02,750000,770000
    2025-05-03,900000,850000
    2025-05-04,700000,760000
    2025-05-05,880000,870000
    """
    df_sales = pd.read_csv(StringIO(sales_csv))
    df_sales["date"] = pd.to_datetime(df_sales["date"])


    # ä»®ã®ç«¶åˆã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿
    events_csv = """date,competitor_event_id,competitor_name,event_power_score
    2025-05-01,E001,åº—A,0.2
    2025-05-03,E002,åº—B,0.8
    2025-05-04,E003,åº—C,0.6
    """
    df_events = pd.read_csv(StringIO(events_csv))
    df_events["date"] = pd.to_datetime(df_events["date"])


    # ãƒ‡ãƒ¼ã‚¿çµåˆ
    df = pd.merge(df_sales, df_events, on="date", how="left")
    df = df[df["competitor_event_id"].notnull()]


    # å£²ä¸Šå¤‰å‹•é¡ã®è¨ˆç®—
    df["delta_sales"] = df["actual_sales"] - df["predicted_sales"]


    # æ•£å¸ƒå›³ãƒ‡ãƒ¼ã‚¿
    df_scatter = df[["event_power_score", "delta_sales"]].dropna()


    # ç›¸é–¢ãƒ»å›å¸°åˆ†æ
    slope, intercept, r_value, _, _ = linregress(df_scatter["event_power_score"], df_scatter["delta_sales"])
    x = np.linspace(0, 1, 100)
    y = slope * x + intercept


    # ã‚°ãƒ©ãƒ•æç”»
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.scatter(df_scatter["event_power_score"], df_scatter["delta_sales"], alpha=0.7)
    ax.plot(x, y, color="red", label=f"ç›¸é–¢R={r_value:.2f}")
    ax.set_xlabel("ç«¶åˆã‚¤ãƒ™ãƒ³ãƒˆå½±éŸ¿ã‚¹ã‚³ã‚¢ (0ã€œ1)")
    ax.set_ylabel("å£²ä¸Šå¤‰å‹•é¡ï¼ˆå††ï¼‰")
    ax.set_title("ç«¶åˆã‚¤ãƒ™ãƒ³ãƒˆã®å½±éŸ¿åº¦ Ã— å£²ä¸Šå¤‰å‹•")
    ax.legend()
    st.pyplot(fig)


    # ãƒ‡ãƒ¼ã‚¿ç¢ºèª
    tab1, tab2 = st.tabs([" ãƒ‡ãƒ¼ã‚¿ä¸€è¦§", " ã‚°ãƒ©ãƒ•ã®ã¿"])
    with tab1:
        st.dataframe(df[["date", "competitor_name", "event_power_score", "actual_sales", "predicted_sales", "delta_sales"]])
    with tab2:
        st.pyplot(fig)


    # èª¬æ˜æ–‡
    st.markdown("""
    ### ã“ã®ãƒšãƒ¼ã‚¸ã§ã‚ã‹ã‚‹ã“ã¨ï¼š
    - **ã‚¤ãƒ™ãƒ³ãƒˆå½±éŸ¿ã‚¹ã‚³ã‚¢ãŒé«˜ã„ç«¶åˆã‚¤ãƒ™ãƒ³ãƒˆ**ã»ã©ã€å£²ä¸Šã«ãƒã‚¤ãƒŠã‚¹ã®å½±éŸ¿ãŒå‡ºã¦ã„ã‚‹ã‹ï¼Ÿã‚’è¦–è¦šçš„ã«æŠŠæ¡ã§ãã¾ã™ã€‚
    - **ç›¸é–¢ä¿‚æ•°ï¼ˆRå€¤ï¼‰** ã«ã‚ˆã£ã¦ã€ã€Œã©ã‚Œãã‚‰ã„ä¸€è²«ã—ãŸå‚¾å‘ãŒã‚ã‚‹ã‹ã€ã‚‚å®šé‡çš„ã«ç¢ºèªå¯èƒ½ã§ã™ã€‚
    - ä»Šå¾Œã®ã‚¤ãƒ™ãƒ³ãƒˆæ—¥ç¨‹èª¿æ•´ã‚„ã€å–¶æ¥­ãƒˆãƒ¼ã‚¯ã§ã®èª¬å¾—ææ–™ã¨ã—ã¦æ´»ç”¨ã§ãã¾ã™ã€‚
    """)


# # 9ãƒšãƒ¼ã‚¸ï¼šå½±éŸ¿ãƒ©ãƒ³ã‚­ãƒ³ã‚°
# elif menu == "å½±éŸ¿ãƒ©ãƒ³ã‚­ãƒ³ã‚°":
#     st.title("ã‚¤ãƒ™ãƒ³ãƒˆå½±éŸ¿ãƒ©ãƒ³ã‚­ãƒ³ã‚°")


#         # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•° ã“ã“ã§æ­£ã—ã„CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµ„ã¿ã“ã‚€
#     def load_merged_dataframe():
#         sales_csv = """date,actual_sales,predicted_sales
#     2025-05-01,800000,820000
#     2025-05-02,750000,770000
#     2025-05-03,900000,850000
#     2025-05-04,700000,760000
#     2025-05-05,880000,870000
#     """
#         df_sales = pd.read_csv(StringIO(sales_csv))
#         df_sales["date"] = pd.to_datetime(df_sales["date"])


#         events_csv = """date,competitor_event_id,competitor_name,event_power_score
#     2025-05-01,E001,åº—A,0.2
#     2025-05-03,E002,åº—B,0.8
#     2025-05-04,E003,åº—C,0.6
#     """
#         df_events = pd.read_csv(StringIO(events_csv))
#         df_events["date"] = pd.to_datetime(df_events["date"])


#         df = pd.merge(df_sales, df_events, on="date", how="left")
#         df = df[df["competitor_event_id"].notnull()]
#         df["delta_sales"] = df["actual_sales"] - df["predicted_sales"]
#         return df




#     # æ¬ æã‚’é™¤å¤–ã—ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä½œæˆ
#     df_filtered = df[df["delta_sales"].notnull()]
#     df_ranked = df_filtered.sort_values(by="delta_sales")


#     st.dataframe(df_ranked[["date", "competitor_name", "event_power_score", "delta_sales"]])




#     st.markdown("###  å£²ä¸Šã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒå¤§ãã‹ã£ãŸã‚¤ãƒ™ãƒ³ãƒˆ Top 5")
#     top5 = df_ranked.head(5)
#     st.bar_chart(top5.set_index("competitor_name")["delta_sales"])


#     st.markdown("###  å£²ä¸Šã«ãƒ—ãƒ©ã‚¹å½±éŸ¿ã‚’ä¸ãˆãŸã‚¤ãƒ™ãƒ³ãƒˆ Top 3")
#     top3_positive = df.sort_values(by="delta_sales", ascending=False).head(3)
#     st.dataframe(top3_positive[["date", "competitor_name", "delta_sales"]])



# ãƒšãƒ¼ã‚¸8ï¼šå¤©å€™ä»˜ãå£²ä¸Šäºˆæ¸¬
# ãƒšãƒ¼ã‚¸8ï¼šå¤©å€™ä»˜ãå£²ä¸Šäºˆæ¸¬
elif st.session_state.selected_page == "å¤©å€™ä»˜ãå£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼":
    st.title("å¤©å€™ä»˜ãå£²ä¸Šäºˆæ¸¬")
    st.write("å¤©å€™ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸå£²ä¸Šäºˆæ¸¬ã®UIã‚’å®Ÿè£…")
    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
# --- ãƒ­ã‚°ã‚¤ãƒ³åº—èˆ—ã‹ã‚‰ãƒ•ã‚©ãƒ«ãƒ€åã‚’å–å¾—ï¼ˆStreamlitã‚»ãƒƒã‚·ãƒ§ãƒ³é€£æºï¼‰
    store_name = st.session_state.get("store_name", "ã‚ªãƒ¼ãƒ‘ã‚¹å®®å´æœ¬åº—")
    store_folder_map = {
        "ã‚ªãƒ¼ãƒ‘ã‚¹å®®å´æœ¬åº—": "miyazaki",
        "ã‚ªãƒ¼ãƒ‘ã‚¹å°æ¾": "komatsudai",
        "ã‚ªãƒ¼ãƒ‘ã‚¹éƒ½åŸåº—": "miyakonojo"
    }
    store_folder = store_folder_map.get(store_name, "miyazaki")

    # --- ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å‹•çš„ã«æ§‹æˆ
    csv_path = f"store_data/{store_folder}/merged_sales_weather.csv"
    model_path = f"store_data/{store_folder}/model_weather.pkl"

    # --- ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆå¤©å€™ä»˜ãäºˆæ¸¬ãƒšãƒ¼ã‚¸ç”¨ï¼‰
    try:
        model = joblib.load(model_path)
        import shap
        explainer = shap.Explainer(model)
    except:
        st.error(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼š{model_path}")
        st.stop()

    # å…¥åŠ›UI
    col1, col2 = st.columns(2)
    æ›œæ—¥_str = col1.selectbox("æ›œæ—¥", ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"], index=0)
    æ›œæ—¥map = {"æœˆ": 0, "ç«": 1, "æ°´": 2, "æœ¨": 3, "é‡‘": 4, "åœŸ": 5, "æ—¥": 6}
    æ›œæ—¥ = æ›œæ—¥map[æ›œæ—¥_str]
    æœˆ = col2.selectbox("æœˆ", list(range(1, 13)), index=6)

    st.markdown("ãƒ›ãƒ¼ãƒ«ãŒèª¿æ•´å¯èƒ½ãªé …ç›®")
    æ‰“è¾¼ = st.slider("æ‰“è¾¼", 5000, 30000, 7000, step=1)
    å°æ•° = st.slider("è¨­ç½®å°æ•°", 300, 1000, 720, step=1)

    st.markdown("å¤–éƒ¨ç’°å¢ƒé …ç›®ï¼ˆå¤©å€™ãƒ»é¡§å®¢ç‰¹æ€§ãªã©ï¼‰")
    å‡ºç‰ç‡ = st.slider("å‡ºç‰ç‡ï¼ˆ%ï¼‰", 85.0, 105.0, 94.0, step=0.1)
    å®¢æ»ç‡ = st.slider("å®¢æ»ç‡ï¼ˆ%ï¼‰", 130.0, 200.0, 165.0, step=0.1)
    å¹³å‡æ°—æ¸© = st.slider("å¹³å‡æ°—æ¸© (â„ƒ)", -5.0, 40.0, 18.0, step=0.5)
    æœ€é«˜æ°—æ¸© = st.slider("æœ€é«˜æ°—æ¸© (â„ƒ)", -5.0, 45.0, 25.0, step=0.5)
    æœ€ä½æ°—æ¸© = st.slider("æœ€ä½æ°—æ¸© (â„ƒ)", -10.0, 30.0, 12.0, step=0.5)
    æ—¥ç…§æ™‚é–“ = st.slider("æ—¥ç…§æ™‚é–“ (h)", 0.0, 15.0, 8.0, step=0.5)
    å¹³å‡æ°—åœ§ = st.slider("å¹³å‡æ°—åœ§ (hPa)", 990.0, 1040.0, 1010.0, step=0.5)
    æœ€å¤§é¢¨é€Ÿ = st.slider("æœ€å¤§é¢¨é€Ÿ (m/s)", 0.0, 40.0, 10.0, step=0.5)
    æœ€å¤§ç¬é–“é¢¨é€Ÿ = st.slider("æœ€å¤§ç¬é–“é¢¨é€Ÿ (m/s)", 0.0, 50.0, 15.0, step=0.5)
    å¹³å‡é¢¨é€Ÿ = st.slider("å¹³å‡é¢¨é€Ÿ (m/s)", 0.0, 20.0, 5.0, step=0.5)
    é™æ°´é‡ = st.slider("é™æ°´é‡ (mm)", 0.0, 200.0, 0.0, step=1.0)

    if st.button("å£²ä¸Šã‚’äºˆæ¸¬ã™ã‚‹"):
        input_data = pd.DataFrame([{
            "æ›œæ—¥_x": æ›œæ—¥,
            "æ‰“è¾¼": æ‰“è¾¼,
            "å‡ºç‰ç‡": å‡ºç‰ç‡,
            "å®¢æ»ç‡": å®¢æ»ç‡,
            "å°æ•°": å°æ•°,
            "å¹³å‡æ°—æ¸©": å¹³å‡æ°—æ¸©,
            "æœ€é«˜æ°—æ¸©": æœ€é«˜æ°—æ¸©,
            "æœ€ä½æ°—æ¸©": æœ€ä½æ°—æ¸©,
            "æ—¥ç…§æ™‚é–“": æ—¥ç…§æ™‚é–“,
            "å¹³å‡æ°—åœ§": å¹³å‡æ°—åœ§,
            "æœ€å¤§é¢¨é€Ÿ": æœ€å¤§é¢¨é€Ÿ,
            "æœ€å¤§ç¬é–“é¢¨é€Ÿ": æœ€å¤§ç¬é–“é¢¨é€Ÿ,
            "å¹³å‡é¢¨é€Ÿ": å¹³å‡é¢¨é€Ÿ,
            "é™æ°´é‡": é™æ°´é‡
        }])

        # CatBoostç”¨ã®ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ãƒªã‚¹ãƒˆï¼ˆãƒ¢ãƒ‡ãƒ«å­¦ç¿’æ™‚ã¨åŒã˜ï¼‰
        cat_features = ["æ›œæ—¥_x", "ç¥æ—¥ãƒ•ãƒ©ã‚°", "çµ¦æ–™æ—¥å‰ãƒ•ãƒ©ã‚°"]

        # å¯¾è±¡ãŒ X ã¾ãŸã¯ input_data ã®ã©ã¡ã‚‰ã‹ï¼ˆãƒšãƒ¼ã‚¸ã”ã¨ã«å¤‰ã‚ã‚‹ï¼‰
        if "X" in locals():
            target_df = X
        elif "input_data" in locals():
            target_df = input_data
        else:
            raise RuntimeError("äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        # å‹å¤‰æ›ï¼ˆé‡è¦ï¼ï¼‰ï¼‹å¿…è¦ãªåˆ—ãŒãªã‘ã‚Œã°è£œå®Œ
        for col in cat_features:
            if col not in target_df.columns:
                target_df[col] = "0"
            target_df[col] = target_df[col].astype(str)

        target_df["æ›œæ—¥_x"] = target_df["æ›œæ—¥_x"].astype(int)
        target_df["ç¥æ—¥ãƒ•ãƒ©ã‚°"] = target_df["ç¥æ—¥ãƒ•ãƒ©ã‚°"].astype(int)
        target_df["çµ¦æ–™æ—¥å‰ãƒ•ãƒ©ã‚°"] = target_df["çµ¦æ–™æ—¥å‰ãƒ•ãƒ©ã‚°"].astype(int)




        from datetime import date

        today = date.today()
        target_df["ç¥æ—¥ãƒ•ãƒ©ã‚°"] = int(today.weekday() in [5, 6]) # åœŸæ—¥ãªã‚‰ç¥æ—¥æ‰±ã„
        target_df["çµ¦æ–™æ—¥å‰ãƒ•ãƒ©ã‚°"] = int(today.day >= 25)    # 25æ—¥ä»¥é™ã‚’çµ¦æ–™æ—¥å‰ã¨ã¿ãªã™



        # ãƒ¢ãƒ‡ãƒ«ã®åˆ—é †ã«æƒãˆã‚‹ï¼ˆè¶…é‡è¦ï¼ï¼‰
        if hasattr(model, "feature_names_"):
            model_features = model.feature_names_
            missing_cols = [col for col in model_features if col not in target_df.columns]
            for col in missing_cols:
                target_df[col] = "0" if col in cat_features else 0
            target_df = target_df[model_features]

# ä¸è¦ãªåˆ—ã‚’å‰Šé™¤
        for col in ["ç¥æ—¥ãƒ•ãƒ©ã‚°", "çµ¦æ–™æ—¥å‰ãƒ•ãƒ©ã‚°"]:
            if col in target_df.columns:
                target_df = target_df.drop(columns=[col])





        pred = model.predict(target_df)[0]
        st.success(f"äºˆæ¸¬å£²ä¸Šï¼šÂ¥{int(pred):,} å††")

        st.markdown("è¦å› åˆ†æï¼ˆSHAPï¼‰")
        try:
            shap_values = explainer(target_df)
            fig = plt.figure()
            shap.plots.waterfall(shap_values[0], show=False)
            st.pyplot(fig)
            plt.close(fig)

            st.markdown("ç‰¹å¾´é‡ã®å½±éŸ¿ï¼ˆä¸Šä½5ã¤ï¼‰")
            top_shap = pd.DataFrame({
                "ç‰¹å¾´é‡": target_df.columns,
                "SHAPå€¤": shap_values[0].values
            }).sort_values("SHAPå€¤", key=abs, ascending=False).head(5)

            for row in top_shap.itertuples():
                impact = "å¢—åŠ " if row.SHAPå€¤ > 0 else "æ¸›å°‘"
                color = "#d9534f" if impact == "å¢—åŠ " else "#0275d8"
                é‡‘é¡ = abs(int(row.SHAPå€¤))
                st.markdown(f"""
                <div style='background-color: #fff; border: 1px solid #ddd; border-left: 8px solid {color}; border-radius: 8px; padding: 12px 16px; margin-bottom: 12px;'>
                    <div style='font-size: 16px; font-weight: bold; color: #333;'>{row.ç‰¹å¾´é‡}</div>
                    <div style='font-size: 14px; margin-top: 4px;'>å£²ä¸ŠãŒ <span style='color:{color}; font-weight: bold;'>ç´„ {é‡‘é¡:,} å†† {impact}ã—ã¾ã—ãŸ</span>ã€‚</div>
                </div>
                """, unsafe_allow_html=True)

        except Exception as e:
            st.error("SHAPã®è§£é‡ˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.exception(e)






#11ãƒšãƒ¼ã‚¸
elif st.session_state.selected_page == "æ™‚é–“å¸¯åˆ¥å®¢æ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—":
    st.title("å®¢æ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
    st.write("æ›œæ—¥ãƒ»æ™‚é–“å¸¯åˆ¥ã®å¹³å‡å®¢æ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è¡¨ç¤º")

    try:
            import seaborn as sns
            import matplotlib.pyplot as plt

            # ---------- âœ… ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ãƒã‚§ãƒƒã‚¯ ----------
            if "store_name" not in st.session_state:
                st.error("ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ­ã‚°ã‚¤ãƒ³ã—ç›´ã—ã¦ãã ã•ã„ã€‚")
                st.stop()

            store_name = st.session_state["store_name"]

            # ---------- âœ… åº—èˆ—å â†’ ãƒ•ã‚¡ã‚¤ãƒ«åãƒãƒƒãƒ”ãƒ³ã‚° ----------
            filename_map = {
                "ã‚ªãƒ¼ãƒ‘ã‚¹å®®å´æœ¬åº—": "hourly_customers_miyazaki.csv",
                "ã‚ªãƒ¼ãƒ‘ã‚¹å°æ¾": "hourly_customers_komatsudai.csv",
                "ã‚ªãƒ¼ãƒ‘ã‚¹éƒ½åŸ": "hourly_customers_miyakonojo.csv",
                # å¿…è¦ã«å¿œã˜ã¦è¿½åŠ 
            }

            if store_name not in filename_map:
                st.error(f"{store_name} ã«å¯¾å¿œã™ã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                st.stop()

            filename = filename_map[store_name]

            # ---------- âœ… CSVèª­ã¿è¾¼ã¿ ----------
            df = pd.read_csv(filename, encoding="utf-8-sig", parse_dates=["datetime", "æ—¥ä»˜"])

            # ---------- âœ… æ›œæ—¥åˆ—ã®è¿½åŠ  ----------
            df["æ›œæ—¥"] = df["æ—¥ä»˜"].dt.weekday
            df["æ›œæ—¥å"] = df["æ›œæ—¥"].map({0: "æœˆ", 1: "ç«", 2: "æ°´", 3: "æœ¨", 4: "é‡‘", 5: "åœŸ", 6: "æ—¥"})

            # ---------- âœ… ãƒ”ãƒœãƒƒãƒˆä½œæˆï¼ˆæ™‚åˆ» Ã— æ›œæ—¥ï¼‰ ----------
            pivot = df.pivot_table(index="æ™‚åˆ»", columns="æ›œæ—¥å", values="å®¢æ•°", aggfunc="mean")

            # æ›œæ—¥é †ã«ä¸¦ã¹æ›¿ãˆ
            weekday_order = ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"]
            pivot = pivot.reindex(columns=weekday_order)

            # ---------- âœ… ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æç”» ----------
            plt.figure(figsize=(10, 6))
            sns.heatmap(pivot, cmap="YlGnBu", annot=True, fmt=".0f", linewidths=0.5)
            plt.title(f"{store_name} ã®æ›œæ—¥ Ã— æ™‚é–“å¸¯ã®å¹³å‡å®¢æ•°", fontsize=14)
            plt.xlabel("æ›œæ—¥")
            plt.ylabel("æ™‚åˆ»")
            plt.tight_layout()

            st.pyplot(plt.gcf())
            plt.clf()

            st.markdown("ã“ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã¯ã€å„æ›œæ—¥ãƒ»æ™‚é–“å¸¯ã”ã¨ã®å¹³å‡å®¢æ•°ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚æ··é›‘å‚¾å‘ã®æŠŠæ¡ã‚„ã‚¹ã‚¿ãƒƒãƒ•é…ç½®ã€åºƒå‘Šã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®æ¤œè¨ã«æ´»ç”¨ã§ãã¾ã™ã€‚")

    except Exception as e:
            st.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¾ãŸã¯åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            st.exception(e)





#12ãƒšãƒ¼ã‚¸ç›®
# --- ãƒšãƒ¼ã‚¸åˆ¤å®š ---
elif st.session_state.selected_page == "æ™‚é–“å¸¯åˆ¥å£²ä¸ŠåŠ¹ç‡åˆ†æ":
    import seaborn as sns
    import matplotlib.pyplot as plt
    import pandas as pd
    import os

    if "store_name" not in st.session_state:
        st.error("ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ­ã‚°ã‚¤ãƒ³ã—ç›´ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # --- ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã®åº—èˆ—åã‚’å–å¾— ---
    store_name = st.session_state["store_name"]
    st.markdown(f"### ğŸ¢ ç¾åœ¨ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã®åº—èˆ—ï¼š**{store_name}**")

    store_folder_map = {
        "ã‚ªãƒ¼ãƒ‘ã‚¹å®®å´æœ¬åº—": "miyazaki",
        "ã‚ªãƒ¼ãƒ‘ã‚¹å°æ¾": "komatsudai",
        "ã‚ªãƒ¼ãƒ‘ã‚¹éƒ½åŸ": "miyakonojo"
    }
    store_folder = store_folder_map.get(store_name, "miyazaki")

    st.title("å£²ä¸ŠåŠ¹ç‡åˆ†æ")
    st.write("1äººã‚ãŸã‚Šå£²ä¸Šã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—åˆ†æ")

    try:
        # --- ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æ§‹ç¯‰ ---
        df_hourly_path = f"store_data/{store_folder}/hourly_customers_long.csv"
        df_sales_path = f"store_data/{store_folder}/merged_sales_weather.csv"

        if not os.path.exists(df_hourly_path) or not os.path.exists(df_sales_path):
            st.warning("åº—èˆ—ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            st.stop()

        # --- æ™‚é–“å¸¯åˆ¥å®¢æ•°ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆutf-8-sigæƒ³å®šï¼‰---
        df_hourly = pd.read_csv(df_hourly_path, encoding="utf-8-sig", parse_dates=["datetime", "æ—¥ä»˜"])

        # --- å£²ä¸Šãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è‡ªå‹•åˆ¤å®šï¼‰---
        try:
            df_sales = pd.read_csv(df_sales_path, encoding="utf-8", parse_dates=["æ—¥ä»˜"])
        except UnicodeDecodeError:
            df_sales = pd.read_csv(df_sales_path, encoding="shift_jis", parse_dates=["æ—¥ä»˜"])

        # --- ç·å®¢æ•°è¨ˆç®— ---
        df_total = df_hourly.groupby("æ—¥ä»˜")["å®¢æ•°"].sum().reset_index().rename(columns={"å®¢æ•°": "ç·å®¢æ•°"})

        # --- ãƒãƒ¼ã‚¸å‡¦ç† ---
        df = df_hourly.merge(df_total, on="æ—¥ä»˜", how="left")
        df = df.merge(df_sales[["æ—¥ä»˜", "å°å£²ä¸Šåˆè¨ˆ"]], on="æ—¥ä»˜", how="left")
        df = df.dropna(subset=["å®¢æ•°", "ç·å®¢æ•°", "å°å£²ä¸Šåˆè¨ˆ"])

        # --- å£²ä¸ŠåŠ¹ç‡è¨ˆç®— ---
        df["æ™‚é–“åˆ¥å£²ä¸Š"] = df["å°å£²ä¸Šåˆè¨ˆ"] * (df["å®¢æ•°"] / df["ç·å®¢æ•°"])
        df["å£²ä¸ŠåŠ¹ç‡"] = df["æ™‚é–“åˆ¥å£²ä¸Š"] / df["å®¢æ•°"]
        df["æ›œæ—¥"] = df["æ—¥ä»˜"].dt.weekday
        df["æ›œæ—¥å"] = df["æ›œæ—¥"].map({0: "æœˆ", 1: "ç«", 2: "æ°´", 3: "æœ¨", 4: "é‡‘", 5: "åœŸ", 6: "æ—¥"})

        # --- ãƒ”ãƒœãƒƒãƒˆï¼ˆæ›œæ—¥Ã—æ™‚åˆ»ï¼‰ ---
        pivot = df.pivot_table(index="æ›œæ—¥å", columns="æ™‚åˆ»", values="å£²ä¸ŠåŠ¹ç‡", aggfunc="mean")
        pivot = pivot.reindex(["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"])

        # --- ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æç”» ---
        plt.figure(figsize=(14, 6))
        sns.heatmap(pivot, cmap="OrRd", annot=True, fmt=".0f", linewidths=0.5)
        plt.title("æ›œæ—¥ Ã— æ™‚é–“å¸¯ã®å£²ä¸ŠåŠ¹ç‡ï¼ˆ1äººã‚ãŸã‚Šå£²ä¸Šï¼‰", fontsize=14)
        plt.xlabel("æ™‚åˆ»")
        plt.ylabel("æ›œæ—¥")
        plt.tight_layout()
        st.pyplot(plt.gcf())
        plt.clf()

        # --- è§£èª¬æ–‡ ---
        st.markdown("""
            ã“ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã¯ã€å„æ™‚é–“å¸¯ã”ã¨ã®å£²ä¸ŠåŠ¹ç‡ï¼ˆ1äººã‚ãŸã‚Šå£²ä¸Šï¼‰ã‚’ç¤ºã—ã¾ã™ã€‚  
            æ··é›‘ã—ã¦ã„ã‚‹æ™‚é–“ã¨åˆ©ç›Šã®å‡ºã‚„ã™ã„æ™‚é–“ã®é•ã„ã‚’æŠŠæ¡ã—ã€æ–½ç­–ã‚„äººå“¡é…ç½®ã«æ´»ç”¨ã§ãã¾ã™ã€‚
        """)

    except Exception as e:
        st.error("å£²ä¸Šã¾ãŸã¯å®¢æ•°ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ãƒ»åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        st.exception(e)



#13ãƒšãƒ¼ã‚¸ç›®
elif st.session_state.selected_page == "æ©Ÿç¨®åˆ¥å„Ÿå´åŠ¹ç‡åˆ†æ":
    store_name = st.session_state.get("store_name", "åº—èˆ—åæœªè¨­å®š")
    st.markdown(f"### ğŸ¢ ç¾åœ¨ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã®åº—èˆ—ï¼š**{store_name}**")

    st.title("æ©Ÿç¨®åˆ¥åˆ†æ(å®®å´æœ¬åº—ã®ã¿å¯¾å¿œ)")
    st.write("æ©Ÿç¨®ã”ã¨ã®å„Ÿå´åŠ¹ç‡ãƒ»ç²—åˆ©åˆ†æã‚’å®Ÿè£…")

    import matplotlib.pyplot as plt
    import seaborn as sns
    import random

    # ã‚¢ãƒ‰ãƒã‚¤ã‚¹æ–‡ç”Ÿæˆé–¢æ•°ï¼ˆãƒšãƒ¼ã‚¸ä¸Šéƒ¨ã«å®šç¾©ã—ã¦ãŠãï¼‰
    def generate_advice(æ©Ÿç¨®å, å„Ÿå´åŠ¹ç‡, ç²—åˆ©, å„Ÿå´é¡):
        if å„Ÿå´åŠ¹ç‡ > 3000:
            opening = random.choice([
                f"ã€Œ{æ©Ÿç¨®å}ã€ã¯ã€ç¾çŠ¶ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¦‹ã¦éå¸¸ã«å„ªã‚ŒãŸé‹ç”¨æˆæœã‚’ä¸Šã’ã¦ãŠã‚Šã€ä»Šå¾Œã®ä¸­æ ¸æ©Ÿç¨®å€™è£œã¨ã„ãˆã¾ã™ã€‚",
                f"ã€Œ{æ©Ÿç¨®å}ã€ã¯ã€ç¾å ´ã«ãŠã„ã¦æ³¨ç›®ã™ã¹ãé«˜åŠ¹ç‡æ©Ÿç¨®ã§ã™ã€‚"
            ])
            detail = random.choice([
                f"1æ—¥ã‚ãŸã‚Šã®ç²—åˆ©ãŒ {ç²—åˆ©:,.0f} å††ã«å¯¾ã—ã€æ—¥å„Ÿå´é¡ã¯ {å„Ÿå´é¡:,.0f} å††ã€‚å·®ã—å¼•ãã§ +{å„Ÿå´åŠ¹ç‡:,.0f} å††ã®åç›Šæ€§ã‚’ç¢ºä¿ã—ã¦ã„ã¾ã™ã€‚",
                f"åæ”¯ãƒãƒ©ãƒ³ã‚¹ã«ãŠã„ã¦å®‰å®šæ„ŸãŒã‚ã‚Šã€ç¾æ™‚ç‚¹ã§ã‚‚ååˆ†ãªåˆ©ç›Šæºã¨ã—ã¦æ©Ÿèƒ½ã—ã¦ã„ã¾ã™ã€‚"
            ])
            suggestion = random.choice([
                "å¢—å°ã‚„ã‚¤ãƒ™ãƒ³ãƒˆã§ã®å„ªé‡é…ç½®ã‚’æ¤œè¨ã™ã‚‹ã“ã¨ã§ã€æ›´ãªã‚‹é›†å®¢ãƒ»åç›Šå¢—åŠ ãŒè¦‹è¾¼ã‚ã¾ã™ã€‚",
                "é‹ç”¨æˆ¦ç•¥ã®æŸ±ã¨ã—ã¦ã€ã‚ˆã‚Šé•·æœŸçš„ãªæ´»ç”¨ã‚‚é¸æŠè‚¢ã«å…¥ã‚‹ã§ã—ã‚‡ã†ã€‚",
                "ã‚ˆã‚Šç©æ¥µçš„ãªè¨´æ±‚ãƒ»ç¨¼åƒå¼·åŒ–ã‚’æ¤œè¨ã™ã‚‹ãƒ•ã‚§ãƒ¼ã‚ºã«ã‚ã‚Šã¾ã™ã€‚"
            ])
            return f"{opening}\n{detail}\n{suggestion}"
        elif å„Ÿå´åŠ¹ç‡ < 0:
            opening = random.choice([
                f"ã€Œ{æ©Ÿç¨®å}ã€ã«ã¤ã„ã¦ã¯ã€ç¾åœ¨ã®å„Ÿå´ãƒãƒ©ãƒ³ã‚¹ã«èª²é¡ŒãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚",
                f"ã€Œ{æ©Ÿç¨®å}ã€ã¯ã€åç›Šæ€§ã«ãŠã„ã¦ã‚„ã‚„ä¸å®‰å®šãªçŠ¶æ³ã«ã‚ã‚Šã¾ã™ã€‚"
            ])
            detail = random.choice([
                f"ç²—åˆ© {ç²—åˆ©:,.0f} å††ã«å¯¾ã—ã€å„Ÿå´é¡ {å„Ÿå´é¡:,.0f} å††ã‚’ä¸‹å›ã£ã¦ãŠã‚Šã€å·®é¡ã¯ {å„Ÿå´åŠ¹ç‡:,.0f} å††ã®ãƒã‚¤ãƒŠã‚¹ã§ã™ã€‚",
                f"ç¾è¡Œã®é‹ç”¨ã‚¹ã‚¿ã‚¤ãƒ«ã§ã¯ã€ç¶™ç¶šçš„ãªèµ¤å­—çŠ¶æ…‹ãŒæƒ³å®šã•ã‚Œã¾ã™ã€‚"
            ])
            suggestion = random.choice([
                "æ—©æœŸã®æ’¤å»ã‚„æ§‹æˆè¦‹ç›´ã—ã‚’å«ã‚ãŸå†æ¤œè¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚",
                "ç¨¼åƒãŒä¼´ã‚ãªã„å ´åˆã€æ©Ÿç¨®ã®ãƒªã‚¹ãƒˆãƒ©ã‚‚å«ã‚ãŸåˆ¤æ–­ãŒæ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚",
                "æ©Ÿç¨®æ§‹æˆã®ã‚¹ãƒªãƒ åŒ–ã‚„ã€ä»–æ©Ÿç¨®ã¸ã®æŠ•è³‡è»¢æ›ã‚’è¦–é‡ã«å…¥ã‚Œã‚‹ã¹ãã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚"
            ])
            return f"{opening}\n{detail}\n{suggestion}"
        else:
            return ""

    try:
        # Excelã®èª­ã¿è¾¼ã¿ã¨ã‚·ãƒ¼ãƒˆçµ±åˆ
        xls = pd.ExcelFile("2025.xlsx")
        if df_merged.empty:
            st.warning("ã“ã®åº—èˆ—ã«ã¯å¯¾å¿œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€ã“ã®ãƒšãƒ¼ã‚¸ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
            st.stop()
        df_merged = pd.concat(
            [xls.parse(sheet).assign(å¯¾è±¡ã‚·ãƒ¼ãƒˆ=sheet) for sheet in xls.sheet_names],
            ignore_index=True
        )

        df_merged.columns = df_merged.iloc[0].astype(str).str.strip()
        df_merged = df_merged.drop(index=0).reset_index(drop=True)

        # æŠ½å‡ºãƒ»å¤‰æ›
        df_use = df_merged[[
            "æ©Ÿç¨®å", "å°æ•°", "å¹³å‡å˜ä¾¡", "é‡‘é¡åˆè¨ˆ", "å–¶æ¥­æ—¥æ•°", "å°ç²—åˆ©", "æœŸé–“å°ç²—åˆ©"
        ]].copy()

        for col in ["å°æ•°", "å¹³å‡å˜ä¾¡", "é‡‘é¡åˆè¨ˆ", "å–¶æ¥­æ—¥æ•°", "å°ç²—åˆ©", "æœŸé–“å°ç²—åˆ©"]:
            df_use[col] = pd.to_numeric(df_use[col], errors="coerce")

        df_use["æ—¥å„Ÿå´é¡"] = df_use["é‡‘é¡åˆè¨ˆ"] / df_use["å–¶æ¥­æ—¥æ•°"]
        df_use["å„Ÿå´åŠ¹ç‡"] = df_use["å°ç²—åˆ©"] - df_use["æ—¥å„Ÿå´é¡"]
        df_sorted = df_use.dropna().sort_values("å„Ÿå´åŠ¹ç‡", ascending=False).reset_index(drop=True)

        top_n = st.slider("è¡¨ç¤ºæ©Ÿç¨®æ•°ï¼ˆä¸Šä½ï¼‰", 5, 110, 30)

        # å„Ÿå´åŠ¹ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        st.markdown("### å„Ÿå´åŠ¹ç‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
        heat_df = df_sorted[["æ©Ÿç¨®å", "å„Ÿå´åŠ¹ç‡"]].head(top_n).set_index("æ©Ÿç¨®å")
        fig, ax = plt.subplots(figsize=(8, int(top_n * 0.35)))
        sns.heatmap(heat_df, annot=True, cmap="RdYlGn", fmt=".0f", linewidths=0.3, ax=ax)
        st.pyplot(fig)
        plt.clf()

        # èµ¤å­—å€™è£œãƒªã‚¹ãƒˆ
        st.markdown("### å„Ÿå´åŠ¹ç‡ãŒãƒã‚¤ãƒŠã‚¹ã®æ©Ÿç¨®ï¼ˆæ’¤å»å€™è£œï¼‰")
        worst_df = df_sorted[df_sorted["å„Ÿå´åŠ¹ç‡"] < 0]
        if worst_df.empty:
            st.success("ã™ã¹ã¦ã®æ©Ÿç¨®ãŒå„Ÿå´ã‚’ä¸Šå›ã‚‹åˆ©ç›Šã‚’å‡ºã—ã¦ã„ã¾ã™ã€‚")
        else:
            st.warning(f"{len(worst_df)}æ©Ÿç¨®ãŒèµ¤å­—çŠ¶æ…‹ã§ã™ã€‚")
            st.dataframe(worst_df[["æ©Ÿç¨®å", "å°ç²—åˆ©", "æ—¥å„Ÿå´é¡", "å„Ÿå´åŠ¹ç‡"]].head(10))

        # è‡ªå‹•ã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼ˆã‚«ãƒ¼ãƒ‰è¡¨ç¤ºï¼‰
        st.markdown("### AIã«ã‚ˆã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹")

        def render_card(row, color):
            advice = generate_advice(row.æ©Ÿç¨®å, row.å„Ÿå´åŠ¹ç‡, row.å°ç²—åˆ©, row.æ—¥å„Ÿå´é¡)
            st.markdown(f"""
            <div style='
                background-color: #fff;
                border: 1px solid #ddd;
                border-left: 8px solid {color};
                border-radius: 8px;
                padding: 12px 16px;
                margin-bottom: 16px;
                box-shadow: 0 1px 3px rgba(0,0,0,0.05);
            '>
                <div style='font-size: 16px; font-weight: bold; color: #333; margin-bottom: 6px;'>
                    {row.æ©Ÿç¨®å}
                </div>
                <div style='font-size: 14px; color: #222; line-height: 1.6; white-space: pre-wrap;'>
                    {advice}
                </div>
                <div style='margin-top: 12px;'>
                    <strong>æ—¥ç²—åˆ©:</strong> Â¥{row.å°ç²—åˆ©:,.0f}ï¼
                    <strong>æ—¥å„Ÿå´é¡:</strong> Â¥{row.æ—¥å„Ÿå´é¡:,.0f}ï¼
                    <strong>å„Ÿå´åŠ¹ç‡:</strong> Â¥{row.å„Ÿå´åŠ¹ç‡:,.0f}
                </div>
            </div>
            """, unsafe_allow_html=True)

        for row in df_sorted.head(3).itertuples():
            render_card(row, "#5cb85c")

        for row in worst_df.head(3).itertuples():
            render_card(row, "#d9534f")

    except Exception as e:
        st.error("ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        st.exception(e)





# #14ãƒšãƒ¼ã‚¸ç›®ç•°å¸¸å€¤æ¤œå‡º
# elif menu == "ç•°å¸¸å€¤æ¤œå‡ºåˆ†æ":
#     st.title("ç•°å¸¸å€¤æ¤œå‡ºãƒšãƒ¼ã‚¸ï¼ˆÂ±2Ïƒï¼‰")
#     try:
#         df = pd.read_excel("ç•°å¸¸å€¤åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿.xlsx")
#         numeric_cols = [col for col in df.select_dtypes(include='number').columns if col not in ["å°æ•°"]]

#         for col in numeric_cols:
#             mu = df[col].mean()
#             sigma = df[col].std()
#             df[f"{col}_ç•°å¸¸"] = ((df[col] < mu - 2 * sigma) | (df[col] > mu + 2 * sigma))

#         anomaly_flags = [f"{col}_ç•°å¸¸" for col in numeric_cols]
#         df_anomalies = df[df[anomaly_flags].any(axis=1)]

#         summary = f"""
#     æœ¬ãƒ¬ãƒãƒ¼ãƒˆã§ã¯ã€ä¸»è¦ãªæ•°å€¤æŒ‡æ¨™ã«å¯¾ã—ã¦æ¨™æº–åå·®Â±2Ïƒã®ç¯„å›²ã‚’åŸºæº–ã¨ã—ãŸç•°å¸¸å€¤æ¤œå‡ºã‚’è¡Œã£ãŸã€‚
#     å…¨ãƒ‡ãƒ¼ã‚¿ã®ã†ã¡ {len(df)} ä»¶ã®ã†ã¡ã€{len(df_anomalies)} ä»¶ã«ç•°å¸¸å€¤ãŒç¢ºèªã•ã‚ŒãŸã€‚
#     ã“ã‚Œã¯å…¨ä½“ã®ç´„ {len(df_anomalies)/len(df)*100:.2f}% ã«ç›¸å½“ã—ã€ç‰¹å®šã®é …ç›®ã«æ¥µç«¯ãªåã‚ŠãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚

#     ã¨ã‚Šã‚ã‘ã€ç•°å¸¸å€¤ã®å¤šãã¯ã€Œ{anomaly_flags[0].replace('_ç•°å¸¸','')}ã€ã€Œ{anomaly_flags[1].replace('_ç•°å¸¸','')}ã€ã¨ã„ã£ãŸæŒ‡æ¨™ã«é›†ä¸­ã—ã¦ãŠã‚Šã€
#     ã“ã‚Œã‚‰ã¯çµŒå–¶çš„ãƒ»å–¶æ¥­çš„ã«è¦‹é€ƒã›ãªã„ã‚·ã‚°ãƒŠãƒ«ã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã€‚
#     ç•°å¸¸ã®å†…å®¹ã«ã¯ã€é€šå¸¸ã‚ˆã‚Šã‚‚æ¥µç«¯ã«é«˜ã„ã¾ãŸã¯ä½ã„æ•°å€¤ãŒå«ã¾ã‚Œã€ç¨¼åƒã®ç•°å¸¸ãƒ»å¤–éƒ¨ã‚¤ãƒ™ãƒ³ãƒˆãƒ»æ§‹æˆã®åã‚Šãªã©ã®åŸå› ãŒè€ƒãˆã‚‰ã‚Œã‚‹ã€‚

#     ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ã€æ—¥æ¬¡ã®ç•°å¸¸å‚¾å‘æŠŠæ¡ã‚„ã€æˆ¦ç•¥è¦‹ç›´ã—ã®èµ·ç‚¹ã¨ã—ã¦æ¥µã‚ã¦æœ‰åŠ¹ã§ã‚ã‚Šã€
#     ç¶™ç¶šçš„ã«åˆ†æã‚’è¡Œã†ã“ã¨ã§ã€ã‚ˆã‚Šå®‰å®šã—ãŸåº—èˆ—é‹å–¶ã¨é«˜ç²¾åº¦ãªæ„æ€æ±ºå®šã‚’æ”¯æ´ã™ã‚‹ã‚‚ã®ã¨ãªã‚‹ã€‚
#     """

#         if st.button("PDFãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›"):
#             pdf = FPDF()
#             pdf.add_page()
#             pdf.add_font("ArialUnicode", '', "arial.ttf", uni=True)
#             pdf.set_font("ArialUnicode", size=12)
#             pdf.multi_cell(0, 10, summary)

#             with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
#                 pdf.output(tmp.name)
#                 with open(tmp.name, "rb") as f:
#                     st.download_button("PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", f, file_name="anomaly_report.pdf")

#     except Exception as e:
#         st.error("PDFå‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
#         st.exception(e)







#16ãƒšãƒ¼ã‚¸
elif st.session_state.selected_page == "AIã‚³ãƒ³ã‚µãƒ«ã‚¢ãƒ‰ãƒã‚¤ã‚¹":
    store_name = st.session_state.get("store_name", "åº—èˆ—åæœªè¨­å®š")
    st.markdown(f"### ğŸ¢ ç¾åœ¨ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã®åº—èˆ—ï¼š**{store_name}**")

    st.title("AIã‚³ãƒ³ã‚µãƒ«ã‚¢ãƒ‰ãƒã‚¤ã‚¹(å®®å´æœ¬åº—ã®ã¿å¯¾å¿œ)")
    st.write("AIã«ã‚ˆã‚‹å–¶æ¥­æ”¹å–„ææ¡ˆã‚’è¡¨ç¤º")

    try:
        xls = pd.ExcelFile("2025.xlsx")
        if df_merged.empty:
            st.warning("ã“ã®åº—èˆ—ã«ã¯å¯¾å¿œã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€ã“ã®ãƒšãƒ¼ã‚¸ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
            st.stop()

        df_merged = pd.concat([
            xls.parse(sheet).assign(å¯¾è±¡ã‚·ãƒ¼ãƒˆ=sheet) for sheet in xls.sheet_names
        ], ignore_index=True)
        df_merged.columns = df_merged.iloc[0].astype(str).str.strip()
        df_merged = df_merged.drop(index=0).reset_index(drop=True)

        df_use = df_merged[["æ©Ÿç¨®å", "å°ç²—åˆ©", "é‡‘é¡åˆè¨ˆ", "å–¶æ¥­æ—¥æ•°"]].copy()
        df_use[["å°ç²—åˆ©", "é‡‘é¡åˆè¨ˆ", "å–¶æ¥­æ—¥æ•°"]] = df_use[["å°ç²—åˆ©", "é‡‘é¡åˆè¨ˆ", "å–¶æ¥­æ—¥æ•°"]].apply(pd.to_numeric, errors="coerce")
        df_use = df_use.dropna()
        df_use["æ—¥å„Ÿå´é¡"] = df_use["é‡‘é¡åˆè¨ˆ"] / df_use["å–¶æ¥­æ—¥æ•°"]
        df_use["å„Ÿå´åŠ¹ç‡"] = df_use["å°ç²—åˆ©"] - df_use["æ—¥å„Ÿå´é¡"]

        æ©Ÿç¨®ä¸€è¦§ = sorted(df_use["æ©Ÿç¨®å"].dropna().unique().tolist())
        machine_name = st.selectbox("æ©Ÿç¨®åã‚’é¸æŠ:", æ©Ÿç¨®ä¸€è¦§)

        selected_row = df_use[df_use["æ©Ÿç¨®å"] == machine_name].iloc[0]
        å„Ÿå´åŠ¹ç‡ = selected_row["å„Ÿå´åŠ¹ç‡"]
        å°ç²—åˆ© = selected_row["å°ç²—åˆ©"]
        å„Ÿå´é¡ = selected_row["æ—¥å„Ÿå´é¡"]

    except Exception as e:
        st.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        machine_name = st.text_input("æ©Ÿç¨®åã‚’å…¥åŠ›:")
        å„Ÿå´åŠ¹ç‡ = st.number_input("å„Ÿå´åŠ¹ç‡ï¼ˆå††ï¼‰", value=0)
        å°ç²—åˆ© = st.number_input("å°ç²—åˆ©ï¼ˆå††ï¼‰", value=0)
        å„Ÿå´é¡ = st.number_input("æ—¥å„Ÿå´é¡ï¼ˆå††ï¼‰", value=0)

    def generate_advice(æ©Ÿç¨®å, å„Ÿå´åŠ¹ç‡, ç²—åˆ©, å„Ÿå´é¡):
        if å„Ÿå´åŠ¹ç‡ > 3000:
            return f"""
        ã€Œ{æ©Ÿç¨®å}ã€ã¯ã€ç¾åœ¨ã®é‹ç”¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¦‹ã¦éå¸¸ã«å„ªã‚ŒãŸæˆç¸¾ã‚’ç¤ºã—ã¦ãŠã‚Šã€
        ä»Šå¾Œã®ä¸»åŠ›æ©Ÿç¨®ã¨ã—ã¦ã®ç¶™ç¶šé…ç½®ã‚„ã€æˆ¦ç•¥çš„ãªé‹ç”¨å¼·åŒ–ã®å€™è£œã¨ã—ã¦æ¤œè¨ã«å€¤ã—ã¾ã™ã€‚

        1æ—¥ã‚ãŸã‚Šã®å°ç²—åˆ©ãŒ {ç²—åˆ©:,.0f} å††ã«å¯¾ã—ã€æ—¥å„Ÿå´é¡ã¯ {å„Ÿå´é¡:,.0f} å††ã€‚
        å·®ã—å¼•ãã§ +{å„Ÿå´åŠ¹ç‡:,.0f} å††ã¨ã„ã†é«˜ã„åç›Šæ€§ã‚’ç¶­æŒã—ã¦ã„ã‚‹ã“ã¨ã‹ã‚‰ã€
        ã“ã®æ©Ÿç¨®ã¯å„Ÿå´ã‚’ååˆ†ã«è¶…éã—ãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¦ã„ã‚‹ã¨è©•ä¾¡ã§ãã¾ã™ã€‚

        ã“ã®æ°´æº–ã§ã®åŠ¹ç‡æ€§ãŒç¶šãå ´åˆã¯ã€å˜ãªã‚‹ç¶­æŒã«ã¨ã©ã¾ã‚‰ãšã€
        å¢—å°ã‚„ã‚¤ãƒ™ãƒ³ãƒˆã§ã®æ³¨åŠ›é…ç½®ã€åºƒå‘Šçš„ãªè¨´æ±‚ã«ã‚ˆã‚‹ç¨¼åƒæ‹¡å¤§ã‚’å›³ã‚‹ã“ã¨ã‚‚ç¾å®Ÿçš„ãªæˆ¦ç•¥ã§ã™ã€‚
        ã¾ãŸã€ä»–æ©Ÿç¨®ã¨ã®æ¯”è¼ƒã«ãŠã„ã¦ã‚‚ã‚³ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒé«˜ãã€
        å•†åœå†…ã§ã®ç«¶åˆå„ªä½æ€§ã‚’ç¢ºä¿ã™ã‚‹ä¸Šã§ã‚‚æœ‰åŠ¹ãªæ–½ç­–ãŒç«‹ã¦ã‚‰ã‚Œã‚‹ã§ã—ã‚‡ã†ã€‚
                """
        elif å„Ÿå´åŠ¹ç‡ < 0:
            return f"""
        ã€Œ{æ©Ÿç¨®å}ã€ã¯ã€ç¾åœ¨ã®é‹ç”¨å®Ÿç¸¾ã«ãŠã„ã¦æ˜ç¢ºãªèª²é¡ŒãŒè¦‹å—ã‘ã‚‰ã‚Œã¾ã™ã€‚
        å°ç²—åˆ©ãŒ {ç²—åˆ©:,.0f} å††ã«ã¨ã©ã¾ã‚‹ä¸€æ–¹ã§ã€æ—¥å„Ÿå´é¡ãŒ {å„Ÿå´é¡:,.0f} å††ã«é”ã—ã¦ãŠã‚Šã€
        ãã®å·®é¡ {å„Ÿå´åŠ¹ç‡:,.0f} å††ã¯ãƒã‚¤ãƒŠã‚¹ã¨ãªã£ã¦ãŠã‚Šã¾ã™ã€‚

        ã“ã®çŠ¶æ³ãŒé•·æœŸåŒ–ã™ã‚‹å ´åˆã€åº—èˆ—å…¨ä½“ã®åç›ŠåŠ¹ç‡ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã€
        çŸ­æœŸçš„ãªç¨¼åƒä¿ƒé€²æ–½ç­–ã«ã‚ˆã‚‹æ”¹å–„ãŒè¦‹è¾¼ã‚ãªã„å ´åˆã«ã¯ã€
        é…ç½®è¦‹ç›´ã—ã‚„æ’¤å»ã€ã¾ãŸã¯ãƒªãƒ‹ãƒ¥ãƒ¼ã‚¢ãƒ«æ©Ÿç¨®ã¸ã®å…¥æ›¿ãªã©ã€
        æ§‹æˆã®å†è¨­è¨ˆãŒæ±‚ã‚ã‚‰ã‚Œã‚‹æ®µéšã¨ã„ãˆã‚‹ã§ã—ã‚‡ã†ã€‚

        æ’¤å»åˆ¤æ–­ã‚’æ€¥ãã¹ãã‹ã©ã†ã‹ã¯ã€ä»Šå¾Œ1é€±é–“ã€œ10æ—¥ã®å‹•å‘æ¬¡ç¬¬ã§ã™ãŒã€
        ç¾æ™‚ç‚¹ã§ã¯â€œå±é™ºæ°´åŸŸâ€ã«ã‚ã‚‹ã“ã¨ã¯ç¢ºã‹ã§ã‚ã‚Šã€å®šé‡çš„ãªè©•ä¾¡ã‚’ã‚‚ã¨ã«ã—ãŸæŸ”è»Ÿãªåˆ¤æ–­ãŒå¿…è¦ã§ã™ã€‚
                """
        else:
            return f"""
        ã€Œ{æ©Ÿç¨®å}ã€ã¯ã€ç¾åœ¨ã®ã¨ã“ã‚å®‰å®šã—ãŸåç›Šæ€§ã‚’ç¶­æŒã—ã¦ãŠã‚Šã€
        å°ç²—åˆ© {ç²—åˆ©:,.0f} å††ã¨æ—¥å„Ÿå´é¡ {å„Ÿå´é¡:,.0f} å††ãŒã»ã¼åŒç­‰ã®æ°´æº–ã§æ¨ç§»ã—ã¦ã„ã¾ã™ã€‚

        å„Ÿå´åŠ¹ç‡ã¯ +{å„Ÿå´åŠ¹ç‡:,.0f} å††ã¨ã‚ãšã‹ãªãŒã‚‰ã®é»’å­—ã§ã™ãŒã€
        ã“ã®çŠ¶æ…‹ãŒç¶™ç¶šã™ã‚‹å ´åˆã€å°æ§‹æˆã®ä¸­ã§â€œä¸­ç«‹çš„â€ãªãƒã‚¸ã‚·ãƒ§ãƒ³ã¨ã—ã¦ç¶­æŒåˆ¤æ–­ãŒå¦¥å½“ã§ã™ã€‚

        ãŸã ã—ã€ä»–æ©Ÿç¨®ã®æ’¤å»ã‚„æ–°æ©Ÿç¨®å°å…¥ã«ã‚ˆã‚‹æ§‹æˆå¤‰åŒ–ãŒã‚ã£ãŸéš›ã«ã¯ã€
        ç›¸å¯¾çš„ã«åˆ©ç›Šè²¢çŒ®åº¦ãŒä½ä¸‹ã™ã‚‹æã‚Œã‚‚ã‚ã‚‹ãŸã‚ã€
        ä»Šå¾Œã®å¤‰åŒ–ã«å¿œã˜ã¦æ³¨è¦–ã‚’ç¶šã‘ã‚‹ã¹ããƒã‚¸ã‚·ãƒ§ãƒ³ã«ã‚ã‚‹ã¨ã„ãˆã¾ã™ã€‚
                """

    if st.button("AIã«ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã‚‚ã‚‰ã†"):
        if machine_name:
            advice = generate_advice(machine_name, å„Ÿå´åŠ¹ç‡, å°ç²—åˆ©, å„Ÿå´é¡)
            st.markdown("### AIã‹ã‚‰ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
            st.success(advice)
        else:
            st.warning("æ©Ÿç¨®åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")





elif st.session_state.selected_page == "å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼vol.2":
    st.title("å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼vol.2")
    st.write("Catboostãƒ¢ãƒ‡ãƒ«")

    import streamlit as st

    # pandasï¼šãƒ‡ãƒ¼ã‚¿å‡¦ç†ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
    import pandas as pd

    import jpholiday

    # CatBoostï¼šã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’ç›´æ¥æ‰±ãˆã‚‹æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
    from catboost import CatBoostRegressor

    # timedeltaï¼šæ—¥ä»˜æ“ä½œç”¨ï¼ˆ1é€±é–“äºˆæ¸¬ã«ä½¿ç”¨ï¼‰
    from datetime import timedelta

    # joblibï¼šãƒ¢ãƒ‡ãƒ«ä¿å­˜ï¼ˆä»Šå›ã¯æœªä½¿ç”¨ã ãŒèª­ã¿è¾¼ã¿ã«ã¯ä¾¿åˆ©ï¼‰
    import joblib

    # --- ãƒ•ãƒ©ã‚°ç”Ÿæˆé–¢æ•°å®šç¾© ---
    def is_payday(date):
        if date.day == 25:
            return 1
        if date.day in [24, 23, 22] and (date + timedelta(days=1)).day == 25 and (date + timedelta(days=1)).weekday() < 5:
            return 1
        return 0

    def is_holiday(date):
        return int(jpholiday.is_holiday(date))

    def is_weekend(date):
        return int(date.weekday() >= 5)

    def is_pension_day(date):
        # å¶æ•°æœˆ15æ—¥ã€ä¼‘æ—¥ãªã‚‰å‰å€’ã—
        if date.month % 2 == 0:
            if date.day == 15:
                return 1
            if date.day in [14, 13, 12] and (date + timedelta(days=1)).day == 15 and (date + timedelta(days=1)).weekday() < 5:
                return 1
    #     return 0

    # # --- Streamlitãƒšãƒ¼ã‚¸ã®åˆæœŸè¨­å®š ---
    # st.set_page_config(page_title="å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼", layout="centered")
    # st.title("ğŸˆ å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼ˆCatBoostãƒ¢ãƒ‡ãƒ«ï¼‰")

    # --- âœ… CSVã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’è¡Œã†ãƒ–ãƒ­ãƒƒã‚¯ ---
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆå‰å‡¦ç†æ¸ˆã®ã‚‚ã®ã‚’æƒ³å®šï¼‰
    # âœ… åº—èˆ—ã«å¿œã˜ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‹•çš„ã«èª­ã¿è¾¼ã¿
    store_name = st.session_state.get("store_name", "åº—èˆ—åæœªè¨­å®š")

    store_code_map = {
        "ã‚ªãƒ¼ãƒ‘ã‚¹å®®å´æœ¬åº—": "miyazaki",
        "ã‚ªãƒ¼ãƒ‘ã‚¹éƒ½åŸ": "miyakonojo",
        "ã‚ªãƒ¼ãƒ‘ã‚¹å°æ¾": "komatsudai"
    }
    store_code = store_code_map.get(store_name)
    if not store_code:
        st.error(f"{store_name} ã«å¯¾å¿œã™ã‚‹åº—èˆ—ã‚³ãƒ¼ãƒ‰ãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    csv_path = f"store_data/{store_code}/merged_sales_weather.csv"
    if not os.path.exists(csv_path):
        st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {csv_path}")
        st.stop()

    try:
        df = load_csv(csv_path, encoding="utf-8", parse_dates=["æ—¥ä»˜"])
    except UnicodeDecodeError:
        df = load_csv(csv_path, encoding="shift_jis", parse_dates=["æ—¥ä»˜"])



    # ä½¿ç”¨ã™ã‚‹åˆ—ã ã‘æŠ½å‡ºï¼ˆåˆ—åã‚’å¾Œã§è‹±èªã«å¤‰æ›ï¼‰
    df = df[[
        "æ—¥ä»˜","æ›œæ—¥_x", "å°æ•°", "å¹³å‡æ°—æ¸©", "é™æ°´é‡", "å°å£²ä¸Šåˆè¨ˆ", "å°å£²ä¸Š", "å°ç²—åˆ©åˆè¨ˆ", "å°ç²—åˆ©", "æ‰“è¾¼",
        "ç·æ‰“è¾¼", "åˆ©ç›Šç‡", "æœ‰åŠ¹S", "å…¥è³S1", "BA", "MY", "å‡ºç‰ç‡", "å®¢æ»ç‡", "ç‰å˜ä¾¡", "ç‰åˆ©", "å‰²æ•°", "å‹ç‡",
        "æ™¯å“é¡å¹³å‡", "æœ€é«˜æ°—æ¸©", "æœ€ä½æ°—æ¸©", "æ—¥ç…§æ™‚é–“(æ™‚é–“)", "å¹³å‡ç¾åœ°æ°—åœ§(hPa)", "æœ€å¤§é¢¨é€Ÿ(m/s)",
        "æœ€å¤§é¢¨é€Ÿ(m/s).2", "å¹³å‡é¢¨é€Ÿ(m/s)"
    ]].copy()

    # åˆ—åã‚’è‹±èªã«å¤‰æ›
    df.columns = [
        "date","weekday", "machine_count", "avg_temp", "precipitation", "total_sales", "unit_sales",
        "total_profit", "unit_profit", "hit", "total_hit", "profit_margin", "effective_s",
        "s1_win", "ba", "my", "payout_rate", "stay_rate", "unit_ball_price", "unit_ball_profit",
        "return_ratio", "win_rate", "avg_prize_value", "max_temp", "min_temp", "sunshine_duration",
        "avg_pressure", "max_wind_speed_1", "max_wind_speed_2", "avg_wind_speed"
    ]

    # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’æ–‡å­—åˆ—å‹ã«å¤‰æ›ï¼ˆweekdayã¯ã‚«ãƒ†ã‚´ãƒªã¨ã™ã‚‹ï¼‰
    df["date"] = pd.to_datetime(df["date"])
    df["weekday"] = df["weekday"].astype(str)

    # --- ãƒ•ãƒ©ã‚°åˆ—è¿½åŠ  ---
    df["payday_flag"] = df["date"].apply(is_payday)
    df["holiday_flag"] = df["date"].apply(is_holiday)
    df["weekend_flag"] = df["date"].apply(is_weekend)
    df["pension_flag"] = df["date"].apply(is_pension_day)


    # ç‰¹å¾´é‡ï¼ˆXï¼‰ã¨ç›®çš„å¤‰æ•°ï¼ˆyï¼‰ã«åˆ†å‰²ï¼ˆå¿…è¦ã«å¿œã˜ã¦ä½¿ã„ãŸã„å¤‰æ•°ã«å¤‰æ›´ï¼‰
    X_train = df[["weekday", "machine_count", "avg_temp", "precipitation",
                "payday_flag", "holiday_flag", "weekend_flag", "pension_flag"]]
    y_train = df["total_sales"]  # â†ä¾‹ã¨ã—ã¦ã€Œå°å£²ä¸Šï¼ˆunit_salesï¼‰ã€ã‚’ç›®çš„å¤‰æ•°ã«

    # å­¦ç¿’å‰ã«NaNã‚’å«ã‚€è¡Œã‚’é™¤å¤–ã™ã‚‹å‡¦ç†ã‚’è¿½åŠ 
    train_data = pd.concat([X_train, y_train], axis=1).dropna()
    X_train = train_data.iloc[:, :-1]
    y_train = train_data.iloc[:, -1]

    # CatBoostãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ï¼ˆã‚«ãƒ†ã‚´ãƒªå¤‰æ•°weekdayã‚’æŒ‡å®šï¼‰
    model = CatBoostRegressor(cat_features=["weekday"], iterations=300, verbose=0)

    model.fit(X_train, y_train)  # å­¦ç¿’é–‹å§‹
    explainer = shap.Explainer(model)

    # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ï¼ˆã‚ã¨ã§å†åˆ©ç”¨å¯èƒ½ï¼‰
    model.save_model("model/merged_sales_catboost.cbm")

    # --- âœ… Streamlitã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹éƒ¨åˆ† ---

    # åº—èˆ—é¸æŠï¼ˆPå°æ•°ãƒ»Så°æ•°ã‚’æ±ºã‚ã‚‹ãŸã‚ï¼‰
    store = st.selectbox("åº—èˆ—", ["ã‚ªãƒ¼ãƒ‘ã‚¹å®®å´æœ¬åº—", "ã‚ªãƒ¼ãƒ‘ã‚¹éƒ½åŸ", "ã‚ªãƒ¼ãƒ‘ã‚¹å°æ¾"])

    # åº—èˆ—ã”ã¨ã®P/Så°æ•°è¨­å®šï¼ˆå›ºå®šå€¤ã ãŒè¾æ›¸ã§ç®¡ç†ï¼‰
    p_table = {"ã‚ªãƒ¼ãƒ‘ã‚¹å®®å´æœ¬åº—": 440, "ã‚ªãƒ¼ãƒ‘ã‚¹éƒ½åŸ": 480, "ã‚ªãƒ¼ãƒ‘ã‚¹å°æ¾": 580}
    s_table = {"ã‚ªãƒ¼ãƒ‘ã‚¹å®®å´æœ¬åº—": 280, "ã‚ªãƒ¼ãƒ‘ã‚¹éƒ½åŸ": 522, "ã‚ªãƒ¼ãƒ‘ã‚¹å°æ¾": 281}
    P = p_table[store]
    S = s_table[store]

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›æ¬„ï¼ˆäºˆæ¸¬å¯¾è±¡ã®æ—¥ä»˜ã€æœŸé–“ã€æ™‚é–“å¸¯ã€å¤©æ°—ï¼‰
    start_date = st.date_input("é–‹å§‹æ—¥")
    forecast_type = st.radio("äºˆæ¸¬æœŸé–“", ["1æ—¥", "1é€±é–“","1ã‹æœˆ(æœˆæœ«ã¾ã§)"], horizontal=True)


    # --- âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸã¨ãã«äºˆæ¸¬ã‚’å®Ÿè¡Œ ---
    if st.button("å£²ä¸Šã‚’äºˆæ¸¬ã™ã‚‹"):
        model = CatBoostRegressor()
        model.load_model("model/merged_sales_catboost.cbm")

        correction_factor = 0.84  # â† å®Ÿç¸¾ã¨ã®ã‚ºãƒ¬ã‚’è£œæ­£ã™ã‚‹ãŸã‚ã®ä¿‚æ•°


        if forecast_type == "1æ—¥":
            target_date = pd.to_datetime(start_date)
            reference_date = target_date - timedelta(days=365)
            weekday = target_date.weekday()

            # 1å¹´å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            past = df[df["date"] == reference_date]
            if not past.empty:
                temp = past["avg_temp"].values[0]
                rain = past["precipitation"].values[0]
            else:
                temp, rain = 25, 0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

            # äºˆæ¸¬ç”¨ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆtempã¨rainã¯ä»®ã§å›ºå®šï¼‰
            X_input = pd.DataFrame([[str(weekday),P+S,temp,rain,
                                    is_payday(target_date),
                                    is_holiday(target_date),
                                    is_weekend(target_date),
                                    is_pension_day(target_date)
                                    ]],
                                columns=["weekday", "machine_count", "avg_temp", "precipitation",
                                            "payday_flag", "holiday_flag", "weekend_flag", "pension_flag"
                                            ])
            y_pred = model.predict(X_input)[0]*correction_factor # äºˆæ¸¬å€¤ã‚’å–å¾—
            # çµæœã‚’è¡¨ç¤º
            st.success(f"ğŸ“… {start_date} ã®äºˆæ¸¬å£²ä¸Šï¼šÂ¥{int(y_pred):,} å††")
            # --- SHAP å¯è¦–åŒ– ---
            st.subheader("ğŸ” ç‰¹å¾´é‡ã®å½±éŸ¿åº¦ï¼ˆSHAPï¼‰")
            shap_values = explainer(X_input)
            fig, ax = plt.subplots()
            shap.plots.waterfall(shap_values[0], max_display=8, show=False)
            st.pyplot(fig)


        elif forecast_type == "1é€±é–“":
            result=[]
            for i in range(7):
                target_date=pd.to_datetime(start_date+timedelta(days=i))
                reference_date = target_date - timedelta(days=365)
                weekday = target_date.weekday()

                past = df[df["date"] == reference_date]
                if not past.empty:
                    temp = past["avg_temp"].values[0]
                    rain = past["precipitation"].values[0]
                else:
                    temp, rain = 25, 0

            
                X_input = pd.DataFrame([[
                    str(weekday), P + S,temp,rain,
                    is_payday(target_date),
                    is_holiday(target_date),
                    is_weekend(target_date),
                    is_pension_day(target_date)
                    ]],columns=["weekday", "machine_count", "avg_temp", "precipitation",
                    "payday_flag", "holiday_flag", "weekend_flag", "pension_flag"
                    ])
                
                y_pred = model.predict(X_input)[0]*correction_factor
                result.append({"æ—¥ä»˜": target_date.date(), "äºˆæ¸¬å£²ä¸Š": int(y_pred)})

            # DataFrameã§ã¾ã¨ã‚ã¦è¡¨ç¤ºãƒ»å¯è¦–åŒ–
            df_result = pd.DataFrame(result)
            st.dataframe(df_result)
            st.line_chart(df_result.set_index("æ—¥ä»˜"))
            # --- SHAPåˆ†æï¼ˆæœ€å¾Œã®æ—¥ä»˜ã®å…¥åŠ›ã‚’ä½¿ç”¨ï¼‰---
            st.subheader("ğŸ“ˆ SHAPåˆ†æï¼ˆæœ€çµ‚æ—¥ï¼‰")
            shap_values = explainer(X_input)  # X_inputã¯ç›´è¿‘ãƒ«ãƒ¼ãƒ—ã§ä½œã‚‰ã‚ŒãŸã‚‚ã®
            fig, ax = plt.subplots()
            shap.plots.waterfall(shap_values[0], max_display=8, show=False)
            st.pyplot(fig)

            total = df_result["äºˆæ¸¬å£²ä¸Š"].sum()
            st.success(f"ğŸ“Š 1é€±é–“ã®äºˆæ¸¬å£²ä¸Šåˆè¨ˆï¼šÂ¥{int(total):,} å††")

        elif forecast_type == "1ã‹æœˆ(æœˆæœ«ã¾ã§)":
            from calendar import monthrange
            year, month = start_date.year, start_date.month
            last_day = monthrange(year, month)[1]
            end_date = start_date.replace(day=last_day)

            forecast_dates = pd.date_range(start=start_date, end=end_date).date

            result = []
            for target_date in forecast_dates:
                reference_date = pd.to_datetime(target_date) - timedelta(days=365)
                weekday = target_date.weekday()

                past = df[df["date"] == reference_date]
                if not past.empty:
                    temp = past["avg_temp"].values[0]
                    rain = past["precipitation"].values[0]
                else:
                    temp, rain = 25, 0

                X_input = pd.DataFrame([[
                    str(weekday), P + S, temp, rain,
                    is_payday(target_date),
                    is_holiday(target_date),
                    is_weekend(target_date),
                    is_pension_day(target_date)
                ]], columns=[
                    "weekday", "machine_count", "avg_temp", "precipitation",
                    "payday_flag", "holiday_flag", "weekend_flag", "pension_flag"
                ])

                y_pred = model.predict(X_input)[0] * correction_factor
                result.append({"æ—¥ä»˜": target_date, "äºˆæ¸¬å£²ä¸Š": int(y_pred)})

            df_result = pd.DataFrame(result)
            st.dataframe(df_result)
            st.line_chart(df_result.set_index("æ—¥ä»˜"))
            # --- SHAPåˆ†æï¼ˆæœ€å¾Œã®æ—¥ä»˜ã®å…¥åŠ›ã‚’ä½¿ç”¨ï¼‰---
            st.subheader("ğŸ“ˆ SHAPåˆ†æï¼ˆæœ€çµ‚æ—¥ï¼‰")
            shap_values = explainer(X_input)  # X_inputã¯ç›´è¿‘ãƒ«ãƒ¼ãƒ—ã§ä½œã‚‰ã‚ŒãŸã‚‚ã®
            fig, ax = plt.subplots()
            shap.plots.waterfall(shap_values[0], max_display=8, show=False)
            st.pyplot(fig)

            total = df_result["äºˆæ¸¬å£²ä¸Š"].sum()
            st.success(f"ğŸ“… 1ã‹æœˆï¼ˆ{start_date.strftime('%Y-%m')}ï¼‰ã®äºˆæ¸¬å£²ä¸Šåˆè¨ˆï¼šÂ¥{int(total):,} å††")
